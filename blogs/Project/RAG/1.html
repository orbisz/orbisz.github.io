<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.19">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <link rel="icon" href="/favicon1.ico"><title>AI-Agent 智能体-开发日志1 | orbisz-Blog</title><meta name="description" content="Carpe diem">
    <link rel="preload" href="/assets/style-BwPacOyM.css" as="style"><link rel="stylesheet" href="/assets/style-BwPacOyM.css">
    <link rel="modulepreload" href="/assets/app-CwN1xCkZ.js"><link rel="modulepreload" href="/assets/1.html-CQTYeHei.js">
    <link rel="prefetch" href="/assets/timeline.html-DnCRnfBK.js" as="script"><link rel="prefetch" href="/assets/posts.html-Blkzsgo_.js" as="script"><link rel="prefetch" href="/assets/friendship-link.html-CVEHcC79.js" as="script"><link rel="prefetch" href="/assets/1.html-QKXFc7Q6.js" as="script"><link rel="prefetch" href="/assets/1.html-D5L-8dpH.js" as="script"><link rel="prefetch" href="/assets/1.html-onNHGmzy.js" as="script"><link rel="prefetch" href="/assets/2.html-COc8hKRU.js" as="script"><link rel="prefetch" href="/assets/1.html-CFojqv3C.js" as="script"><link rel="prefetch" href="/assets/2.html-BrkCCNiu.js" as="script"><link rel="prefetch" href="/assets/1.html-7rSKJ0sK.js" as="script"><link rel="prefetch" href="/assets/2.html-CBvInC3x.js" as="script"><link rel="prefetch" href="/assets/1.html-C94hVs-F.js" as="script"><link rel="prefetch" href="/assets/1.html-0DVIUx77.js" as="script"><link rel="prefetch" href="/assets/1.html-BfSbxCjI.js" as="script"><link rel="prefetch" href="/assets/1.html-Byg1dxtM.js" as="script"><link rel="prefetch" href="/assets/1.html-EuM7P5XC.js" as="script"><link rel="prefetch" href="/assets/1.html-CMZxFXEP.js" as="script"><link rel="prefetch" href="/assets/1.html-vnIrEMRY.js" as="script"><link rel="prefetch" href="/assets/2.html-kIaHsIgQ.js" as="script"><link rel="prefetch" href="/assets/1.html-C9q13f_C.js" as="script"><link rel="prefetch" href="/assets/1.html-Cj1RB6Bw.js" as="script"><link rel="prefetch" href="/assets/1.html-DEHWVrAt.js" as="script"><link rel="prefetch" href="/assets/1.html-AagTBXVJ.js" as="script"><link rel="prefetch" href="/assets/1.html-9HfCBwRF.js" as="script"><link rel="prefetch" href="/assets/1.html-BaWzHnTx.js" as="script"><link rel="prefetch" href="/assets/2.html-D-TMJvZ-.js" as="script"><link rel="prefetch" href="/assets/1.html-DAwqZe-N.js" as="script"><link rel="prefetch" href="/assets/1.html-DlARmrfq.js" as="script"><link rel="prefetch" href="/assets/1.html-MpMlTxbw.js" as="script"><link rel="prefetch" href="/assets/1.html-CNmotZVt.js" as="script"><link rel="prefetch" href="/assets/2.html-CAnUgCus.js" as="script"><link rel="prefetch" href="/assets/1.html-BUsLGL8W.js" as="script"><link rel="prefetch" href="/assets/1.html-DXeuuKpN.js" as="script"><link rel="prefetch" href="/assets/1.html-BtMqpYVv.js" as="script"><link rel="prefetch" href="/assets/1.html-BGXfTft4.js" as="script"><link rel="prefetch" href="/assets/1.html-ZWMZ9vQl.js" as="script"><link rel="prefetch" href="/assets/1.html-AagTBXVJ.js" as="script"><link rel="prefetch" href="/assets/1.html-3Eg93AQk.js" as="script"><link rel="prefetch" href="/assets/1.html-ChRZFyOF.js" as="script"><link rel="prefetch" href="/assets/1.html-tD7gaCjV.js" as="script"><link rel="prefetch" href="/assets/1.html-yWiZBQ0e.js" as="script"><link rel="prefetch" href="/assets/1.html-3Eg93AQk.js" as="script"><link rel="prefetch" href="/assets/1.html-BVqnulkd.js" as="script"><link rel="prefetch" href="/assets/1.html-DzH1PSOr.js" as="script"><link rel="prefetch" href="/assets/1.html-DJt1WQ7X.js" as="script"><link rel="prefetch" href="/assets/1.html-C1F83DCP.js" as="script"><link rel="prefetch" href="/assets/1.html-Bu6CmXR8.js" as="script"><link rel="prefetch" href="/assets/1.html-XG0VYcJz.js" as="script"><link rel="prefetch" href="/assets/1.html-BBZjDuqR.js" as="script"><link rel="prefetch" href="/assets/1.html-BpOhgIbW.js" as="script"><link rel="prefetch" href="/assets/1.html-BLwdrwsM.js" as="script"><link rel="prefetch" href="/assets/1.html-Bl-9Je1v.js" as="script"><link rel="prefetch" href="/assets/1.html-BEkjqVQh.js" as="script"><link rel="prefetch" href="/assets/1.html-BQ-DMhZS.js" as="script"><link rel="prefetch" href="/assets/1.html-BhPexvfB.js" as="script"><link rel="prefetch" href="/assets/1.html-8LTVDnP7.js" as="script"><link rel="prefetch" href="/assets/2.html-CH3Lfqg2.js" as="script"><link rel="prefetch" href="/assets/3.html-BdHsJeXt.js" as="script"><link rel="prefetch" href="/assets/4.html-DMQ4auV-.js" as="script"><link rel="prefetch" href="/assets/5.html-DfN9xCVf.js" as="script"><link rel="prefetch" href="/assets/index.html-WdhsPlA4.js" as="script"><link rel="prefetch" href="/assets/message-board.html-CfmbgH4M.js" as="script"><link rel="prefetch" href="/assets/1.html-DBI8bgSa.js" as="script"><link rel="prefetch" href="/assets/paper1.html-fV6wB6YA.js" as="script"><link rel="prefetch" href="/assets/1.html-DNAgNDZA.js" as="script"><link rel="prefetch" href="/assets/2.html-C5R4Autn.js" as="script"><link rel="prefetch" href="/assets/3.html-DK6af9JM.js" as="script"><link rel="prefetch" href="/assets/5.html-DPsLJMw7.js" as="script"><link rel="prefetch" href="/assets/graph.html-5CIBCBrB.js" as="script"><link rel="prefetch" href="/assets/offer-java.html-Cta5X4Zq.js" as="script"><link rel="prefetch" href="/assets/offer-java2.html-BIsde5Aw.js" as="script"><link rel="prefetch" href="/assets/offer-java3.html-BWHyTuTk.js" as="script"><link rel="prefetch" href="/assets/paixu.html-CTlhvtwY.js" as="script"><link rel="prefetch" href="/assets/stackandheap.html-CzYar6IN.js" as="script"><link rel="prefetch" href="/assets/tanxin.html-Bd8QFkI8.js" as="script"><link rel="prefetch" href="/assets/union.html-C-rIowYH.js" as="script"><link rel="prefetch" href="/assets/DI.html-BTUBN0Yq.js" as="script"><link rel="prefetch" href="/assets/MVCC.html-lou3MBhW.js" as="script"><link rel="prefetch" href="/assets/mysql.html-BOQ4NhUE.js" as="script"><link rel="prefetch" href="/assets/RDBandAOF.html-_I4G8B7g.js" as="script"><link rel="prefetch" href="/assets/SpringBootStarter.html-DEWEniVA.js" as="script"><link rel="prefetch" href="/assets/xitongshejitu.html-D0H_S4nZ.js" as="script"><link rel="prefetch" href="/assets/yuanma.html-W_MFSUut.js" as="script"><link rel="prefetch" href="/assets/2.html-4MRJZlyG.js" as="script"><link rel="prefetch" href="/assets/1.html-JSBUOibm.js" as="script"><link rel="prefetch" href="/assets/OpenAI2025.html-fELH9QrW.js" as="script"><link rel="prefetch" href="/assets/DDD.html-CeHEEIZG.js" as="script"><link rel="prefetch" href="/assets/docker.html-Cfisb4jT.js" as="script"><link rel="prefetch" href="/assets/1.html-DxAdDHD2.js" as="script"><link rel="prefetch" href="/assets/1.html-DFi3O1D_.js" as="script"><link rel="prefetch" href="/assets/mybatis.html-BRMASDPi.js" as="script"><link rel="prefetch" href="/assets/Netty.html-C-cqc81w.js" as="script"><link rel="prefetch" href="/assets/1.html-BGDrYRAq.js" as="script"><link rel="prefetch" href="/assets/dayingxiao.html-DvQFx-9p.js" as="script"><link rel="prefetch" href="/assets/dayingxiao1.html-DmwAH1zk.js" as="script"><link rel="prefetch" href="/assets/dayingxiao2.html-D1l-P9nb.js" as="script"><link rel="prefetch" href="/assets/dayingxiao3.html-40uKAzj-.js" as="script"><link rel="prefetch" href="/assets/dayingxiao4.html-BZbRh9nA.js" as="script"><link rel="prefetch" href="/assets/mybatis.html-B4ZxjtR7.js" as="script"><link rel="prefetch" href="/assets/IM.html-DirPUTan.js" as="script"><link rel="prefetch" href="/assets/guide.html-6OjT6Zzq.js" as="script"><link rel="prefetch" href="/assets/2.html-DORNh2MT.js" as="script"><link rel="prefetch" href="/assets/3.html-ClM1MjTW.js" as="script"><link rel="prefetch" href="/assets/4.html-DsFL8_Ty.js" as="script"><link rel="prefetch" href="/assets/4.html-Bwskl05a.js" as="script"><link rel="prefetch" href="/assets/5.html-DyEMkrlQ.js" as="script"><link rel="prefetch" href="/assets/wrench1.html-BZhhs7Bn.js" as="script"><link rel="prefetch" href="/assets/wrench2.html-LDT9UiS9.js" as="script"><link rel="prefetch" href="/assets/wrench3.html-Cu9ImrE_.js" as="script"><link rel="prefetch" href="/assets/404.html-DKeMwnuU.js" as="script"><link rel="prefetch" href="/assets/Valine.min-_LyT3bfY.js" as="script"><link rel="prefetch" href="/assets/giscus-aTimukGI-DWEKOTfS.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container series--no show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/logo1.jpg" alt="orbisz-Blog"><a href="/" class="site-name can-hide">orbisz-Blog</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><a href="/" class="link" aria-label="首页"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconHome class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconHome><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->首页<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/docs/message-board" class="link" aria-label="留言板"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconChat class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconChat><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->留言板<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a class="link" href="https://blog.csdn.net/hywzxy" target="_blank" rel="noopener noreferrer" aria-label="CSDN"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconCSDN class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconCSDN><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->CSDN<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a class="link" href="https://github.com/orbisz" target="_blank" rel="noopener noreferrer" aria-label="Github"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconGithub class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconGithub><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Github<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="项目体验"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->项目体验<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="项目体验"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->项目体验<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a class="link" href="http://117.72.164.204:3000/?userId=zxy&amp;activityId=100301" target="_blank" rel="noopener noreferrer" aria-label="幸运营销汇"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->幸运营销汇<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a class="link" href="http://101.43.191.204" target="_blank" rel="noopener noreferrer" aria-label="Ai-Agent 智能体 "><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ai-Agent 智能体 <!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--><!----><span class="xicon-container btn-toggle-dark-mode btn--dark-mode navbar-links__item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><ul class="social-links navbar-links__item"><!--[--><!--]--></ul></nav><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><!----><!----><!----><div class="theme-main" style=""><!----><!--[--><main class="page-container"><div class="page-content"><h1 class="page-title">AI-Agent 智能体-开发日志1</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->orbisz<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2025/07/16<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/categories/houduankaifa/1.html" class="">后端开发</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M10 14a4 4 0 1 1 4-4a4.005 4.005 0 0 1-4 4zm0-6a2 2 0 1 0 1.998 2.004A2.002 2.002 0 0 0 10 8z" fill="currentColor"></path><path d="M16.644 29.415L2.586 15.354A2 2 0 0 1 2 13.941V4a2 2 0 0 1 2-2h9.941a2 2 0 0 1 1.414.586l14.06 14.058a2 2 0 0 1 0 2.828l-9.943 9.943a2 2 0 0 1-2.829 0zM4 4v9.942L18.058 28L28 18.058L13.942 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/tags/DeepSeek/1.html" class="">DeepSeek</a><a href="/tags/qianhouduanfenli/1.html" class="">前后端分离</a><a href="/tags/SpringAI/1.html" class="">SpringAI</a><a href="/tags/Flux/1.html" class="">Flux</a><a href="/tags/ostgresql/1.html" class="">ostgresql</a><a href="/tags/Redis/1.html" class="">Redis</a><a href="/tags/Nginx/1.html" class="">Nginx</a><a href="/tags/Docker/1.html" class="">Docker</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;font-size:18px;" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 12 12"><g fill="none"><path d="M1.974 6.659a.5.5 0 0 1-.948-.317c-.01.03 0-.001 0-.001a1.633 1.633 0 0 1 .062-.162c.04-.095.099-.226.18-.381c.165-.31.422-.723.801-1.136C2.834 3.827 4.087 3 6 3c1.913 0 3.166.827 3.931 1.662a5.479 5.479 0 0 1 .98 1.517l.046.113c.003.008.013.06.023.11L11 6.5s.084.333-.342.474a.5.5 0 0 1-.632-.314v-.003l-.006-.016a3.678 3.678 0 0 0-.172-.376a4.477 4.477 0 0 0-.654-.927C8.584 4.673 7.587 4 6 4s-2.584.673-3.194 1.338a4.477 4.477 0 0 0-.795 1.225a2.209 2.209 0 0 0-.03.078l-.007.018zM6 5a2 2 0 1 0 0 4a2 2 0 0 0 0-4zM5 7a1 1 0 1 1 2 0a1 1 0 0 1-2 0z" fill="currentColor"></path></g></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><span id="/blogs/Project/RAG/1.html" class="leancloud-visitors" data-flag-title="Your Article Title"><a class="leancloud-visitors-count" style=""></a></span><!----><!--]--></span></span></div><div class="theme-reco-md-content"><div><p><strong>RAG:检索增强生成</strong></p><p>RAG是一种结合了信息检索技术与语言生成模型的人工智能技术，从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型，以增强模型处理知识密集型任务的能力。 RAG是一种 AI 框架，它将传统信息检索系统（例如数据库）的优势与生成式大语言模型 (LLM) 的功能结合在一起。是从知识库中检索到的问答对，增强了LLM的提示词（prompt），LLM拿着增强后的Prompt生成了问题答案。</p><p>LLM面临两个问题</p><ul><li>知识截止：当 LLM 返回的信息与模型的训练数据相比过时时。每个基础模型都有知识截止（指LLM的“知识库”是有冻结时间的。模型的训练数据只更新到某个特定日期，此后的世界变化、新事件、新发现，模型都无从知晓）， 这意味着其知识仅限于训练时可用的数据。</li><li>当模型自信地做出错误反应时，就会发生幻觉。</li></ul><p>基于通用语言模型通过微调就可以完成几类常见任务，比如分析情绪和识别命名实体。这些任务不需要额外的背景知识就可以完成。</p><p>要完成更复杂和知识密集型的任务，可以基于语言模型构建一个系统，访问外部知识源来做到。这样的实现与事实更加一致，生成的答案更可靠，还有助于缓解“幻觉”问题。</p><p>Meta AI 的研究人员引入了一种叫做检索增强生成（Retrieval Augmented Generation，RAG）的方法来完成这类知识密集型的任务。 RAG 把一个信息检索组件和文本生成模型结合在一起。RAG 可以微调，其内部知识的修改方式很高效，不需要对整个模型进行重新训练。</p><p>RAG 会接受输入并检索出一组相关/支撑的文档，并给出文档的来源（例如维基百科）。这些文档作为上下文和输入的原始提示词组合，送给文本生成器得到最终的输出。 这样 RAG 更加适应事实会随时间变化的情况。这非常有用，因为 LLM 的参数化知识是静态的。RAG 让语言模型不用重新训练就能够获取最新的信息，基于检索生成产生可靠的输出。</p><p>对于一个Git项目或者一个工程的全部SQL，我们需要对工程信息发起提问，但不想每次都从工程或者SQL中做整理，那么就可以把这些信息提交给知识库。 那么每次提问的时候选择对应的知识库，就可以帮我们携带文本向量匹配知识，之后进行一起提交给 AI 大模型来提问，如图： <img src="/assets/img_1-Bm3IJru9.png" alt="img_1.png"> 文本知识库可以是非常多种的类型，不非得限定到文字，也可以是sql或者java代码。那么这里我们就可以解析一类是上传的文件，一类是Git代码库的项目。 也可以是来自网页的内容之后爬虫。这些内容都可以被解析处理。</p><p>把文件进行切割，存储到向量模型。存储的时候要对文件进行打标，标记出属于哪个知识库。甚至你可以做的更细致，比如，项目工程时，这是什么包下的什么类。都可以打标。 完事后存储到向量库。这个也就是说所说的文本向量化。</p><p>最后，在进行提问的时候，以提交的问题和问题到向量库检索，一起合并信息进行提问，这样提问的信息描述会更加定向准确，也就可以获得更好的回答。 如，我们问的是，请对大营销项目SQL语句，生产对应的所有JavaPO对象。那么这个时候就会反馈类信息了。也可以为运营伙伴提供必要的SQL语句请提供我要查询xxx、yyy、zzz数据，在什么时间产生的数据，他们也就不用非得找研发要SQL语句了。这样就可以帮助企业提效了。</p><h2 id="第一阶段" tabindex="-1"><a class="header-anchor" href="#第一阶段"><span>第一阶段</span></a></h2><h3 id="ollama-deepseek-流式应答接口实现" tabindex="-1"><a class="header-anchor" href="#ollama-deepseek-流式应答接口实现"><span>Ollama DeepSeek 流式应答接口实现</span></a></h3><p>引入 Spring AI 框架组件，对接 Ollama DeepSeek 提供服务接口。包括；普通应答接口和流式接口。</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line"># 拉取模型，推荐小一点，够做开发就可以</span>
<span class="line">ollama pull deepseek-r1:1.5b</span>
<span class="line"></span>
<span class="line"># （可选）运行模型，运行后关闭，继续安装模型。Ctrl/Command + D</span>
<span class="line">ollama run deepseek-r1:1.5b</span>
<span class="line"></span>
<span class="line"># 向量文本</span>
<span class="line">ollama pull nomic-embed-text</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>nomic-embed-text：是一款由 Nomic AI 开发的开源文本嵌入模型，专门用于将文本转化为向量（数值数组）。 它擅长捕捉文本的语义信息，生成的向量可用于语义搜索、文本聚类、相似性比对等场景,可以在RAG应用中作为向量数据库的嵌入工具。</p><p><strong>注意</strong> ：也许是因为配置版本问题，Application扫描不到其他的模块，因此引入了</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">@ComponentScan({</span>
<span class="line">        &quot;cn.bugstack.orbisz.ai.rag.api&quot;,      // 接口包</span>
<span class="line">        &quot;cn.bugstack.orbisz.ai.rag.app&quot;,      // 主模块包</span>
<span class="line">        &quot;cn.bugstack.orbisz.ai.rag.trigger&quot;   // 依赖模块包</span>
<span class="line">})</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>已解决</strong>，是因为Application的位置不对，没有放在cn.bugstack.orbisz.ai，所以扫描不到其他的包</p><h3 id="ollama-deepseek-流式应答接口实现-1" tabindex="-1"><a class="header-anchor" href="#ollama-deepseek-流式应答接口实现-1"><span>Ollama DeepSeek 流式应答接口实现</span></a></h3><p>引入 Spring AI 框架组件，对接 Ollama DeepSeek 提供服务接口。包括；普通应答接口和流式接口。</p><ul><li>在 IAiAgentChatService 接口中定义了 aiAgentChatStream 方法.</li><li>AiAgentChatService 类作为实现类，具体实现了流式对话逻辑</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">@Override</span>
<span class="line">public Flux&lt;ChatResponse&gt; aiAgentChatStream(Long aiAgentId, Long ragId, String message) {</span>
<span class="line">    // 查询模型ID</span>
<span class="line">    Long modelId = repository.queryAiClientModelIdByAgentId(aiAgentId);</span>
<span class="line">    // 获取对话模型</span>
<span class="line">    ChatModel chatModel = defaultArmoryStrategyFactory.chatModel(modelId);</span>
<span class="line">    // 构建消息列表</span>
<span class="line">    List&lt;Message&gt; messages = new ArrayList&lt;&gt;();</span>
<span class="line">    </span>
<span class="line">    // 处理RAG增强逻辑</span>
<span class="line">    if (null != ragId &amp;&amp; 0 != ragId) {</span>
<span class="line">        // 省略RAG相关代码...</span>
<span class="line">    } else {</span>
<span class="line">        messages.add(new UserMessage(message));</span>
<span class="line">    }</span>
<span class="line">    </span>
<span class="line">    // 关键：调用模型的stream方法获取Flux流</span>
<span class="line">    return chatModel.stream(Prompt.builder()</span>
<span class="line">            .messages(messages)</span>
<span class="line">            .build());</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Controller接口暴露</strong></p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">@RequestMapping(value = &quot;chat_stream&quot;, method = RequestMethod.GET)</span>
<span class="line">@Override</span>
<span class="line">public Flux&lt;ChatResponse&gt; chatStream(@RequestParam(&quot;aiAgentId&quot;) Long aiAgentId, </span>
<span class="line">                                    @RequestParam(&quot;ragId&quot;) Long ragId, </span>
<span class="line">                                    @RequestParam(&quot;message&quot;) String message) {</span>
<span class="line">    try {</span>
<span class="line">        log.info(&quot;AiAgent 智能体对话(stream)，请求 {} {} {}&quot;, aiAgentId, ragId, message);</span>
<span class="line">        return aiAgentChatService.aiAgentChatStream(aiAgentId, ragId, message);</span>
<span class="line">    } catch (Exception e) {</span>
<span class="line">        log.error(&quot;AiAgent 智能体对话(stream)，失败 {} {} {}&quot;, aiAgentId, ragId, message, e);</span>
<span class="line">        throw e;</span>
<span class="line">    }</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过AI工具实现一款简单的UI界面与服务端 Ollama DeepSeek AI 进行对接。</p><ul><li>前端通过 EventSource 建立 SSE (Server-Sent Events) 连接接收流式响应，实现在 js/index.js 中的 startEventStream 函数。</li></ul><p><strong>Flux的优势</strong></p><ol><li>实时响应体验 ：用户可以立即看到生成的内容，而不需要等待整个响应完成</li><li>更好的用户体验 ：减少用户感知的等待时间，提高交互流畅度</li><li>渐进式内容展示 ：内容可以逐字逐句显示，模拟人类思考和打字的过程</li><li>资源优化 ：服务端和客户端可以边生成边传输，避免一次性处理大量数据</li><li>更快的首字时间(TTFB) ：用户能更快看到第一个响应内容，减少感知延迟</li></ol><p><strong>流式响应出错的恢复方式</strong></p><ol><li>Controller层异常处理 ：在 AiAgentController 的 chatStream 方法中，捕获异常并记录日志后重新抛出</li><li>客户端错误处理 ：在测试代码 AiAgentTest.java 中，通过 stream.subscribe() 的错误处理器 Throwable::printStackTrace 处理流错误</li><li>缺少专门恢复机制 ：项目中没有实现针对流式响应的专门恢复机制，如断点续传、自动重试等高级策略</li></ol><p><strong>流式数据的延迟处理</strong></p><ol><li>线程调度优化 ：在 RagAnswerAdvisor.java 中，使用 publishOn(Schedulers.boundedElastic()) 来处理可能的阻塞操作，避免阻塞响应线程</li><li>超时配置 ：在测试代码中配置了 requestTimeout(Duration.ofMinutes(180)) 长时间超时，以适应大模型可能的长处理时间</li><li>缺少高级延迟处理 ：项目中没有实现基于背压(backpressure)的流量控制、自适应延迟处理等高级机制</li></ol><h3 id="ollama-rag-知识库上传、解析和验证" tabindex="-1"><a class="header-anchor" href="#ollama-rag-知识库上传、解析和验证"><span>Ollama RAG 知识库上传、解析和验证</span></a></h3><p>以 Spring AI 提供的向量模型处理框架，将上传文件以 TikaDocumentReader 方式进行解析，再通过 TokenTextSplitter 拆分文件。完成这些操作后，在遍历文档添加标记。标记的作用是为了可以区分不同的知识库内容。完成这些动作后，把这些拆解并打标的文件存储到 postgresql 向量库中。</p><p>本技术方案旨在利用 Spring AI 提供的向量模型处理框架，对上传的文件进行解析、拆分、标记，并将处理后的数据存储到 PostgreSQL 向量库中。通过这一流程，可以实现对文件内容的高效管理和检索，特别是在需要区分不同知识库内容的场景下。</p><ul><li>SpringAI : 提供向量模型处理框架，支持文件的解析、拆分和向量化操作。</li><li>TikaDocumentReader : 用于解析上传的文件，支持多种文件格式（如 MD、TXT、SQL 等）。</li><li>TokenTextSplitter : 用于将解析后的文本内容拆分为更小的片段，便于后续处理和存储。</li><li>PostgreSQL向量库 : 用于存储处理后的文本向量数据，支持高效的相似性搜索和检索。</li></ul><p><strong>RAG 知识库索引构建流程</strong></p><ol><li>文档读取 ：使用 TikaDocumentReader 读取各种格式的文件（如文本、PDF、Word等）</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">TikaDocumentReader documentReader = new TikaDocumentReader(file.getResource());</span>
<span class="line">List&lt;Document&gt; documentList = documentReader.get();</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>文档分割 ：通过 TokenTextSplitter 将长文档分割成适当大小的文本块，确保每个块能够被嵌入模型有效处理</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">List&lt;Document&gt; documentSplitterList = tokenTextSplitter.apply(documentList);</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="3"><li>添加元数据 ：为每个文档块添加知识库标签等元数据信息</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">documentSplitterList.forEach(doc -&gt; doc.getMetadata().put(&quot;knowledge&quot;, tag));</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="4"><li>向量化与存储 ：调用 PgVectorStore 的 accept 方法，将文本块转换为向量并存储到 PostgreSQL 数据库</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">vectorStore.accept(documentSplitterList);</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="5"><li>配置记录 ：将知识库配置信息（名称、标签等）存储到 MySQL 数据库中，用于管理和查询</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">AiRagOrderVO aiRagOrderVO = new AiRagOrderVO();</span>
<span class="line">aiRagOrderVO.setRagName(name);</span>
<span class="line">aiRagOrderVO.setKnowledgeTag(tag);</span>
<span class="line">repository.createTagOrder(aiRagOrderVO);</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>技术实现细节</strong></p><ul><li>向量存储配置 ：在 <code>AiAgentConfig.java</code> 中，项目为 PgVector 配置了专用的数据源和 JdbcTemplate</li><li>向量模型 ：使用 OpenAI 的嵌入模型将文本转换为向量，进行文本向量化处理。</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">OpenAiEmbeddingModel embeddingModel = new OpenAiEmbeddingModel(openAiApi);</span>
<span class="line">return PgVectorStore.builder(jdbcTemplate, embeddingModel)</span>
<span class="line">        .vectorTableName(&quot;vector_store_openai&quot;)</span>
<span class="line">        .build();</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>数据表结构 ：通过初始化脚本创建了专用的向量存储表，包含内容、元数据和向量字段</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">CREATE TABLE public.vector_store_openai (</span>
<span class="line">    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),</span>
<span class="line">    content TEXT NOT NULL,</span>
<span class="line">    metadata JSONB,</span>
<span class="line">    embedding VECTOR(1536)</span>
<span class="line">);</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>TokenTextSplitter 是基于 token 数量进行文本切分，并不能按照段落换行对文本进行切分。自定义了文本切分器CustomTextSplitter</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">public class CustomTextSplitter extends TextSplitter {</span>
<span class="line"></span>
<span class="line">    private final String paragraphSeparator;</span>
<span class="line"></span>
<span class="line">    public CustomTextSplitter(String paragraphSeparator) {</span>
<span class="line">        this.paragraphSeparator = paragraphSeparator;</span>
<span class="line">    }</span>
<span class="line"></span>
<span class="line">    @Override</span>
<span class="line">    protected List&lt;String&gt; splitText(String text) {</span>
<span class="line">        if (text == null || text.isEmpty()) {</span>
<span class="line">            return new ArrayList&lt;&gt;();</span>
<span class="line">        }</span>
<span class="line">        //将输入的文本（text）按行分割（默认换行符 \n），并过滤掉空行，返回非空行的列表。</span>
<span class="line">        return Arrays.stream(text.split(&quot;\\n&quot;))</span>
<span class="line">                .filter(line -&gt; !line.trim().isEmpty())</span>
<span class="line">                .toList();</span>
<span class="line">    }</span>
<span class="line"></span>
<span class="line">    @Override</span>
<span class="line">    public List&lt;Document&gt; apply(List&lt;Document&gt; documents) {</span>
<span class="line">        List&lt;Document&gt; result = new ArrayList&lt;&gt;();</span>
<span class="line">        for (Document doc : documents) {</span>
<span class="line">            //按自定义分隔符（paragraphSeparator）分割为段落</span>
<span class="line">            String[] paragraphs = doc.getContent().split(paragraphSeparator);</span>
<span class="line">            for (String paragraph : paragraphs) {</span>
<span class="line">                Document newDoc = new Document(paragraph.trim());</span>
<span class="line">                result.add(newDoc);</span>
<span class="line">            }</span>
<span class="line">        }</span>
<span class="line">        return result;</span>
<span class="line">    }</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollama-rag-知识库接口服务实现" tabindex="-1"><a class="header-anchor" href="#ollama-rag-知识库接口服务实现"><span>Ollama RAG 知识库接口服务实现</span></a></h3><p>以上一节知识库的测试案例，将这部分功能以接口方式提供。包括；知识库的上传、选择和使用。</p><p>知识库的上传和使用是明确的，但选择哪个知识库是需要把对应的知识库记录起来。这里我们选择 Redis 列表进行记录。如果是公司里大型的知识库，还需要使用 MySQL 数据库进行存储。</p><p>基于我们要实现对话和知识的上传使用，使用AI工具完成UI页面的实现。</p><p>所有已创建的知识库标签存储在Redis中。</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">documents.forEach(doc -&gt; doc.getMetadata().put(&quot;knowledge&quot;, ragTag));  // 原始文档添加标签</span>
<span class="line">documentSplitterList.forEach(doc -&gt; doc.getMetadata().put(&quot;knowledge&quot;, ragTag));  // 分割后的文档添加标签</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>确保原始文档和分割后的文本块都能被正确关联到同一知识库标签</p><h3 id="git仓库代码库解析到知识库" tabindex="-1"><a class="header-anchor" href="#git仓库代码库解析到知识库"><span>Git仓库代码库解析到知识库</span></a></h3><p>对知识库的解析进行扩展，增加Git仓库解析。用户填写Git仓库地址和账密，即可拉取代码并上传到知识库，之后就可以基于这套代码进行使用啦。</p><p>引入 JGit 操作库到工程中，用于执行 Git 命令拉取代码仓库。之后对代码库文件进行遍历，依次解析分割上传到向量库中。</p><h3 id="扩展openai模型对接-以及完整ai对接" tabindex="-1"><a class="header-anchor" href="#扩展openai模型对接-以及完整ai对接"><span>扩展OpenAI模型对接，以及完整AI对接</span></a></h3><p>基于 Spring AI 扩展 OpenAI 模型对接，这样我们就可以使用一些代理的 ChatGPT 接口完成对话了。最终在完成全部接口与页面的对接。</p><p>Spring AI 框架的好处，就是可以以统一的方式直接配置使用各类大模型。像是一些 Spring AI 没有直接对接的大模型，可以基于 one-api 配置转发，用统一 OpenAI 方式进行对接。</p><ul><li>统一的对话记忆组件 ：使用 PromptChatMemoryAdvisor 配合 MessageWindowChatMemory 实现对话历史存储和管理</li><li>全局对话ID标识 ：通过 CHAT_MEMORY_CONVERSATION_ID_KEY 参数（如 chatId-101 ）统一标识对话会话</li><li>记忆容量配置 ：在数据库 ai_client_advisor 表中配置了 ChatMemory 类型的顾问， maxMessages 设置为200，控制记忆窗口大小</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">// 记忆组件创建</span>
<span class="line">return new PromptChatMemoryAdvisor(MessageWindowChatMemory.builder()</span>
<span class="line">        .maxMessages(chatMemory.getMaxMessages())</span>
<span class="line">        .build());</span>
<span class="line"></span>
<span class="line">// 对话调用时指定统一对话ID</span>
<span class="line">content = chatClient.prompt(message)</span>
<span class="line">        .advisors(a -&gt; a</span>
<span class="line">                .param(CHAT_MEMORY_CONVERSATION_ID_KEY, &quot;chatId-101&quot;)</span>
<span class="line">                .param(CHAT_MEMORY_RETRIEVE_SIZE_KEY, 100))</span>
<span class="line">        .call().content();</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>问题1：如何保证多轮对话的上下文连贯性（如用户追问时如何传递历史对话）？</strong></p><ol><li>前端采用localStorage实现对话历史的本地存储和管理： <ul><li>对话唯一标识 ：每个对话都有唯一的 chatId （基于时间戳生成）</li><li>对话数据结构 ：每个对话包含 name 和 messages 数组， messages 数组存储用户和AI的交互消息</li><li>当前对话追踪 ：通过 currentChatId 变量和localStorage中的同名key追踪当前活动对话</li><li>消息存储 ：发送新消息时，先将用户消息保存到localStorage，收到AI回复后再保存回复内容</li></ul></li><li>后端通过Spring AI框架提供的对话记忆组件实现上下文管理： <ul><li>对话记忆组件 ：使用 PromptChatMemoryAdvisor 配合 MessageWindowChatMemory 组件管理对话历史</li><li>对话ID统一标识 ：通过 CHAT_MEMORY_CONVERSATION_ID_KEY 参数（当前硬编码为 chatId-101 ）标识对话会话</li><li>记忆窗口大小 ：通过 maxMessages 参数（默认配置为200）控制对话记忆的最大消息数量</li><li>历史消息检索量 ：通过 CHAT_MEMORY_RETRIEVE_SIZE_KEY 参数控制每次请求时检索的历史消息数量</li></ul></li></ol><h2 id="第二阶段" tabindex="-1"><a class="header-anchor" href="#第二阶段"><span>第二阶段</span></a></h2><p>升级 Spring AI 框架到 1.0.0-M6 版本，以适应于二阶段 MCP（Model Context Protocol 模型上下文协议）服务开发。</p><p>DeepSeek 的模型对应的向量维度为 768；OpenAI 的模型对应的向量维度为 1536；</p><h3 id="康庄大道-上手-ai-mcp-工作流" tabindex="-1"><a class="header-anchor" href="#康庄大道-上手-ai-mcp-工作流"><span>康庄大道，上手 AI MCP 工作流</span></a></h3><p>对接 Spring AI MCP，实现服务端 MCP 和 客户端 MCP，完成功能对接，体验 AI 工作流完成的指令动作。 目前对接的这套 mcp 服务是文件处理的服务，它可以读取、设置、操作你的文件。也就是 AI 对话的过程中，可以操作你的文件信息。</p><p>基础AI（如ChatGPT）仅能生成文本回复（“说”），而 MCP 赋予AI调用工具的能力（“做”），例如操作文件、查询系统信息等。（严格来说，MCP 是 工具的管理和通信框架，而具体的工具（如 <code>filesystem</code>、<code>mcp-server-computer</code>）才是能力的提供者）</p><p>mcp的配置需要在application.yml等配置文件中配好，指定好引入哪些mcp服务，如下：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">{    &quot;mcpServers&quot;: {  </span>
<span class="line">    &quot;filesystem&quot;: {  </span>
<span class="line">        &quot;command&quot;: &quot;cmd&quot;,  </span>
<span class="line">        &quot;args&quot;: [  </span>
<span class="line">            &quot;/c&quot;,  </span>
<span class="line">            &quot;npx&quot;,  </span>
<span class="line">            &quot;-y&quot;,  </span>
<span class="line">            &quot;@modelcontextprotocol/server-filesystem&quot;,  </span>
<span class="line">            &quot;D:\\OneDrive\\桌面&quot;,  </span>
<span class="line">            &quot;D:\\OneDrive\\桌面&quot;  </span>
<span class="line">        ]  </span>
<span class="line">    },  </span>
<span class="line">    &quot;mcp-server-computer&quot;: {  </span>
<span class="line">        &quot;command&quot;: &quot;C:\Users\zhangxiuyu\.jdks\corretto-17.0.12\bin\java.exe&quot;,  </span>
<span class="line">        &quot;args&quot;: [  </span>
<span class="line">            &quot;-Dspring.ai.mcp.server.stdio=true&quot;,  </span>
<span class="line">            &quot;-jar&quot;,  </span>
<span class="line">            &quot;D:\\code\\idea\\xfg\\mcp-server-computer\\target\\mcp-server-computer-1.0.0.jar&quot;  </span>
<span class="line">        ]  </span>
<span class="line">    }  </span>
<span class="line">}  }</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里引入了两个mcp服务，上面的是别人实现好的包，提供系统文件操作功能；下面是我们自己用java实现的工具包，提供获取电脑配置功能 不管用什么语言编写，只要服务遵循了MCP的通信协议（如 Stdio），就能被其他项目作为mcp服务引入</p><p>具体到我们实现的项目中，因为注册了</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre><code><span class="line"><span class="token annotation punctuation">@Bean</span>  </span>
<span class="line"><span class="token keyword">public</span> <span class="token class-name">ToolCallbackProvider</span> <span class="token function">computerTools</span><span class="token punctuation">(</span><span class="token class-name">ComputerService</span> computerService<span class="token punctuation">)</span> <span class="token punctuation">{</span>  </span>
<span class="line">    <span class="token keyword">return</span> <span class="token class-name">MethodToolCallbackProvider</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toolObjects</span><span class="token punctuation">(</span>computerService<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个bean，就遵循了Spring AI 的 IPC 通信协议。在项目应用中配置好以后，就能通过</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre><code><span class="line"><span class="token annotation punctuation">@Autowired</span>  </span>
<span class="line"><span class="token keyword">private</span> <span class="token class-name">ToolCallbackProvider</span> tools<span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>注入。</p><p>这里是一个门面模式，项目所有配置的mcp服务都能被引入这一个tools中来 然后在调api的过程中通过spring ai提供的mcp框架（如下）就能实现mcp加持的ai功能</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre><code><span class="line"><span class="token keyword">var</span> chatClient <span class="token operator">=</span> chatClientBuilder  </span>
<span class="line">        <span class="token punctuation">.</span><span class="token function">defaultTools</span><span class="token punctuation">(</span>tools<span class="token punctuation">)</span>  </span>
<span class="line">        <span class="token punctuation">.</span><span class="token function">defaultOptions</span><span class="token punctuation">(</span><span class="token class-name">OllamaOptions</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  </span>
<span class="line">                <span class="token punctuation">.</span><span class="token function">model</span><span class="token punctuation">(</span><span class="token string">&quot;gpt-4.1-mini&quot;</span><span class="token punctuation">)</span>  </span>
<span class="line">                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  </span>
<span class="line">        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;\n&gt;&gt;&gt; ASSISTANT: &quot;</span> <span class="token operator">+</span> chatClient<span class="token punctuation">.</span><span class="token function">prompt</span><span class="token punctuation">(</span>userInput<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">content</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>总之，如果我们想开发mcp服务，只需实现好想实现的功能后，配置好mcp通信即可（例如java是ToolCallbackProvider的bean） 如果我们想应用mcp服务到自己的项目，只需在配置里引入，然后注入到ToolCallbackProvider，利用spring ai提供的框架，调用api即可</p><h3 id="道山学海-实现mcp自动发帖服务-stdio" tabindex="-1"><a class="header-anchor" href="#道山学海-实现mcp自动发帖服务-stdio"><span>道山学海，实现MCP自动发帖服务（stdio）</span></a></h3><p>分析 CSDN 文章发表接口，以 MCP 服务搭建的方式，实现一款 stdio 模式的 CSDN 发帖 MCP 服务。（后续开发 sse 模式）</p><p>如图，实现 CSDN 发帖 MCP 服务流程: <img src="/assets/img_2-D-tkye11.png" alt="img_2.png"></p><ul><li>首先，无论你是对接任何的平台，都是需要先获得他的接口服务。这种接口一种是平台提供了专门的对接接口，另外就是没有这样的接口，我们是通过浏览器访问网站，获得的接口。哪这些接口通过代码方式完成请求。</li><li>之后，基于得到的接口，封装成可以调用的服务 service，这样 MCP 的入口工具，设定好入参信息，就可以调用底层的接口服务了。</li><li>最后，当用户提问时，如果你实现了不止一个 CSDN 发帖的 MCP，也包括如星球发帖。那么你的 AI 工作流，是可以顺序的向这些平台自动发帖。</li></ul><h3 id="海纳百川-上线mcp自动发帖服务" tabindex="-1"><a class="header-anchor" href="#海纳百川-上线mcp自动发帖服务"><span>海纳百川，上线MCP自动发帖服务</span></a></h3><p>以 Jar 包的形式，打包 MCP 自动发帖服务，并以 stdio 方式引入到项目工程。再通过定时任务触达定时自动发帖。 <img src="/assets/img_3-DQQYWLxK.png" alt="img_3.png"></p><ul><li>首先，将 mcp-server-csdn 以 maven 命令方式打一个 jar。IntelliJ IDEA 也可以直接通过界面操作打包 Jar（视频里会演示）</li><li>之后，将 ai-mcp-knowledge 以 maven 命令方式打一个 jar，并执行 Dockerfile 构建出可部署的镜像。注意，这里额外增加一个阿里云 Docker 镜像仓库，为的是让他提供搭理，方便我们云服务器部署的时候，可以快速拉取下来镜像。此外，如果说你以云服务器当做本机一样使用，在云服务器配置好 maven、git、java jdk 17，那么就可以在云服务器直接构建镜像，也就不需要额外拉取了。（这部分内容在课程入口-编程环境-云服务器操作中有讲解）</li><li>最后，通过 docker-compose 脚本配置上线部署。</li></ul><p>先增加一个 trigger 模块，在这个模块下添加 job 任务。定时的调用 ai mcp 服务，完成文章的编写和推送。</p><h3 id="川流不息-实现mcp微信公众号消息通知" tabindex="-1"><a class="header-anchor" href="#川流不息-实现mcp微信公众号消息通知"><span>川流不息，实现MCP微信公众号消息通知</span></a></h3><p>AI MCP 是可以让 AI 以工作流方式进行调用的，为了更好的体现这一点，同时也为了增强整体的自动发帖服务链路。本节我们实现一个微信公众号推送消息的 MCP 服务。</p><p>这一节暂时会先以 stdio 方式开发，之后下一节部署的时候，会把 CSDN、WeiXin 两个 MCP 服务都以 SSE 方式进行部署。 <img src="/assets/img_4-ChgG_6k3.png" alt="img_4.png"></p><ul><li>实现一个微信公众号推送模板消息的实现。</li><li>之后，AI 调用两套 MCP，可以一次会话，也可以使用 ChatMemory 进行记忆完成2次对话处理 MCP 流程。</li><li>最终，实现自动发帖后，完成消息通知给我们自己。点击通知信息可进入具体文章。</li></ul><p>在发帖服务 port.writeArticle(request); 返回对接 ArticleFunctionResponse 增加文章信息，包括；url、description。这样我们在通知给微信公众号模板消息的时候，就能知道文章的地址了。</p><p>之后，CSDNPort#writeArticle 返回的 articleFunctionResponse 封装下文章信息即可。</p><p>MCP本质就是对接接口，并以AI识别的方式进行调用</p><h3 id="息息相通-mcp-服务部署上线-sse-模式" tabindex="-1"><a class="header-anchor" href="#息息相通-mcp-服务部署上线-sse-模式"><span>息息相通，MCP 服务部署上线（sse 模式）</span></a></h3><p>调整 mcp-server-csdn、mcp-server-weixin，两个 MCP 部署方式为 SSE 以及增加 Dockerfile 部署脚本。让服务支持以 sse 方式，被 ai-mcp-knowledge 调用。 <img src="/assets/img_5-D7WPc6xi.png" alt="img_5.png"></p><ul><li>SSE (Server-Sent Events) ，是一种基于 HTTP 的服务器向客户端单向实时推送数据 的通信技术，常用于实现实时更新功能。浏览器通过 EventSource 对象向服务器发起一个 长连接，服务器可以不断地向客户端推送文本数据（通常是 UTF-8 编码的 JSON 或纯文本），而不需要客户端轮询。，属于应用层技术。 <ul><li>简单易用： 直接基于 HTTP 协议，不需要像 WebSocket 那样进行复杂的协议升级； 前端直接 new EventSource(url) 就能接收数据。</li><li>轻量低成本： 复用现有 HTTP 基础设施（Nginx/负载均衡/防火墙）即可； 消息格式简单，使用纯文本传输。</li><li>自动重连： 浏览器原生支持断线自动重连（不需要额外逻辑）。</li><li>单向推送场景足够： 适合 服务端 → 客户端 的实时通知、日志流、任务进度推送等场景。</li><li>比轮询更高效： 避免频繁轮询，降低服务器负载和带宽消耗。</li></ul></li><li>在 Spring AI 框架中，SSE 的实现方式包括 spring-ai-starter-mcp-server-webmvc、spring-ai-starter-mcp-server-webflux 两种框架实现。课程以 webflux 进行使用。</li><li>SSE 的部署方式，要把每个 mcp 服务，通过 docker 进行部署，提供出可用的接口。之后 ai-mcp-knowledge 工程则配置 sse 方式进行使用。</li></ul><p>ai-mcp-knowledge项目既是MCP客户端（Client），又是MCP服务端（Server）</p><ul><li>被其他 MCP Client 调用（作为 Server）；</li><li>同时去调用其他 MCP Server（作为 Client）；</li><li>用于串联多个 Agent，执行链式任务。</li></ul><p>mcp-server-csdn项目是一个纯MCPServer项目</p><ul><li>提供基于 WebFlux 的 HTTP + SSE 服务端口；</li><li>通常作为被调用方存在（被 ai-mcp-knowledge 项目远程调用）；</li><li>通过配置 spring.ai.mcp.server.stdio=true 也可以兼容本地 STDIO 模式（非必须）。</li></ul><p><strong>问题1：为什么MCPServer有三种传输模式？</strong></p><p>MCP Server 是「工具能力的提供方 」，它的核心作用是： 等待 MCP Client 发来请求，并根据注册的工具逻辑，执行任务并返回结果。 所以Server必须提供不同的传输协议支持，来应对部署环境的差异。</p><p><strong>问题2：为什么 MCP Client 只有“标准客户端”和“WebFlux客户端”两种</strong> MCP Client 的核心职责是发起工具调用请求并接收服务器响应，其通信模式更聚焦于 “如何高效对接 Server 的传输模式”，而非支持多样化接入。因此设计更精简。 强调“标准客户端支持STDIO和SSE”是为了强调</p><ul><li>如果你希望调用“本地 MCP Server 工具”，可使用 STDIO 通信；</li><li>如果你希望远程调用 MCP Server（通常是 WebMVC/WebFlux 实现），使用 SSE；</li><li>同一个Client可以组合连接多个Server（STDIO本地工具+远程HTTP工具） 。</li></ul><p><strong>问题3：为什么建议“生产使用WebFluxSSE”客户端？</strong></p><ul><li>WebFlux 是响应式、非阻塞的，适合处理多个并发的流式回复（如 LLM token 输出）；</li><li>对于 AI 场景来说，SSE 的 token streaming 是典型需求；</li><li>WebFlux Client 更适合部署到 API Gateway、任务编排系统、Bot 平台等。</li></ul><p>决定同步 vs 异步方式的根本：你注入哪个 MCP Client 接口，即通过你注入的是 McpClient 还是 ReactiveMcpClient 决定的；</p><p>鉴权机制（Authentication &amp; Authorization Mechanism）是信息安全领域的核心组件，主要用于验证用户/系统的身份合法性（鉴权，Authentication），并控制其访问资源的权限范围（授权，Authorization）。 简单来说，它回答两个关键问题：</p><ul><li>“你是谁？”（鉴权：确认身份真实性）</li><li>“你能做什么？”（授权：确认可访问的资源与操作） 基于CSDN用户的cookies验证身份</li></ul></div></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->最近更新 2025/8/8 21:24:49<!--]--></span></span></div></footer><!----><div class="reco-valine-wrapper"><div id="valine"></div></div></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/Project/RAG/1.html#第一阶段" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="第一阶段"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->第一阶段<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#ollama-deepseek-流式应答接口实现" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Ollama DeepSeek 流式应答接口实现"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ollama DeepSeek 流式应答接口实现<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#ollama-deepseek-流式应答接口实现-1" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Ollama DeepSeek 流式应答接口实现"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ollama DeepSeek 流式应答接口实现<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#ollama-rag-知识库上传、解析和验证" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Ollama RAG 知识库上传、解析和验证"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ollama RAG 知识库上传、解析和验证<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#ollama-rag-知识库接口服务实现" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Ollama RAG 知识库接口服务实现"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ollama RAG 知识库接口服务实现<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#git仓库代码库解析到知识库" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Git仓库代码库解析到知识库"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Git仓库代码库解析到知识库<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#扩展openai模型对接-以及完整ai对接" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="扩展OpenAI模型对接，以及完整AI对接"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->扩展OpenAI模型对接，以及完整AI对接<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/Project/RAG/1.html#第二阶段" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="第二阶段"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->第二阶段<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#康庄大道-上手-ai-mcp-工作流" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="康庄大道，上手 AI MCP 工作流"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->康庄大道，上手 AI MCP 工作流<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#道山学海-实现mcp自动发帖服务-stdio" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="道山学海，实现MCP自动发帖服务（stdio）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->道山学海，实现MCP自动发帖服务（stdio）<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#海纳百川-上线mcp自动发帖服务" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="海纳百川，上线MCP自动发帖服务"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->海纳百川，上线MCP自动发帖服务<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#川流不息-实现mcp微信公众号消息通知" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="川流不息，实现MCP微信公众号消息通知"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->川流不息，实现MCP微信公众号消息通知<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/Project/RAG/1.html#息息相通-mcp-服务部署上线-sse-模式" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="息息相通，MCP 服务部署上线（sse 模式）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->息息相通，MCP 服务部署上线（sse 模式）<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--]--></ul></div></main><!--]--></div></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CwN1xCkZ.js" defer></script>
  </body>
</html>
