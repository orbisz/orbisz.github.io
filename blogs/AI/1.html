<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.19">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <link rel="icon" href="/favicon1.ico"><title>AI Agent 基础了解 | orbisz-Blog</title><meta name="description" content="Carpe diem">
    <link rel="preload" href="/assets/style-BwPacOyM.css" as="style"><link rel="stylesheet" href="/assets/style-BwPacOyM.css">
    <link rel="modulepreload" href="/assets/app-CwN1xCkZ.js"><link rel="modulepreload" href="/assets/1.html-DBI8bgSa.js">
    <link rel="prefetch" href="/assets/timeline.html-DnCRnfBK.js" as="script"><link rel="prefetch" href="/assets/posts.html-Blkzsgo_.js" as="script"><link rel="prefetch" href="/assets/friendship-link.html-CVEHcC79.js" as="script"><link rel="prefetch" href="/assets/1.html-QKXFc7Q6.js" as="script"><link rel="prefetch" href="/assets/1.html-D5L-8dpH.js" as="script"><link rel="prefetch" href="/assets/1.html-onNHGmzy.js" as="script"><link rel="prefetch" href="/assets/2.html-COc8hKRU.js" as="script"><link rel="prefetch" href="/assets/1.html-CFojqv3C.js" as="script"><link rel="prefetch" href="/assets/2.html-BrkCCNiu.js" as="script"><link rel="prefetch" href="/assets/1.html-7rSKJ0sK.js" as="script"><link rel="prefetch" href="/assets/2.html-CBvInC3x.js" as="script"><link rel="prefetch" href="/assets/1.html-C94hVs-F.js" as="script"><link rel="prefetch" href="/assets/1.html-0DVIUx77.js" as="script"><link rel="prefetch" href="/assets/1.html-BfSbxCjI.js" as="script"><link rel="prefetch" href="/assets/1.html-Byg1dxtM.js" as="script"><link rel="prefetch" href="/assets/1.html-EuM7P5XC.js" as="script"><link rel="prefetch" href="/assets/1.html-CMZxFXEP.js" as="script"><link rel="prefetch" href="/assets/1.html-vnIrEMRY.js" as="script"><link rel="prefetch" href="/assets/2.html-kIaHsIgQ.js" as="script"><link rel="prefetch" href="/assets/1.html-C9q13f_C.js" as="script"><link rel="prefetch" href="/assets/1.html-Cj1RB6Bw.js" as="script"><link rel="prefetch" href="/assets/1.html-DEHWVrAt.js" as="script"><link rel="prefetch" href="/assets/1.html-AagTBXVJ.js" as="script"><link rel="prefetch" href="/assets/1.html-9HfCBwRF.js" as="script"><link rel="prefetch" href="/assets/1.html-BaWzHnTx.js" as="script"><link rel="prefetch" href="/assets/2.html-D-TMJvZ-.js" as="script"><link rel="prefetch" href="/assets/1.html-DAwqZe-N.js" as="script"><link rel="prefetch" href="/assets/1.html-DlARmrfq.js" as="script"><link rel="prefetch" href="/assets/1.html-MpMlTxbw.js" as="script"><link rel="prefetch" href="/assets/1.html-CNmotZVt.js" as="script"><link rel="prefetch" href="/assets/2.html-CAnUgCus.js" as="script"><link rel="prefetch" href="/assets/1.html-BUsLGL8W.js" as="script"><link rel="prefetch" href="/assets/1.html-DXeuuKpN.js" as="script"><link rel="prefetch" href="/assets/1.html-BtMqpYVv.js" as="script"><link rel="prefetch" href="/assets/1.html-BGXfTft4.js" as="script"><link rel="prefetch" href="/assets/1.html-ZWMZ9vQl.js" as="script"><link rel="prefetch" href="/assets/1.html-AagTBXVJ.js" as="script"><link rel="prefetch" href="/assets/1.html-3Eg93AQk.js" as="script"><link rel="prefetch" href="/assets/1.html-ChRZFyOF.js" as="script"><link rel="prefetch" href="/assets/1.html-tD7gaCjV.js" as="script"><link rel="prefetch" href="/assets/1.html-yWiZBQ0e.js" as="script"><link rel="prefetch" href="/assets/1.html-3Eg93AQk.js" as="script"><link rel="prefetch" href="/assets/1.html-BVqnulkd.js" as="script"><link rel="prefetch" href="/assets/1.html-DzH1PSOr.js" as="script"><link rel="prefetch" href="/assets/1.html-DJt1WQ7X.js" as="script"><link rel="prefetch" href="/assets/1.html-C1F83DCP.js" as="script"><link rel="prefetch" href="/assets/1.html-Bu6CmXR8.js" as="script"><link rel="prefetch" href="/assets/1.html-XG0VYcJz.js" as="script"><link rel="prefetch" href="/assets/1.html-BBZjDuqR.js" as="script"><link rel="prefetch" href="/assets/1.html-BpOhgIbW.js" as="script"><link rel="prefetch" href="/assets/1.html-BLwdrwsM.js" as="script"><link rel="prefetch" href="/assets/1.html-Bl-9Je1v.js" as="script"><link rel="prefetch" href="/assets/1.html-BEkjqVQh.js" as="script"><link rel="prefetch" href="/assets/1.html-BQ-DMhZS.js" as="script"><link rel="prefetch" href="/assets/1.html-BhPexvfB.js" as="script"><link rel="prefetch" href="/assets/1.html-8LTVDnP7.js" as="script"><link rel="prefetch" href="/assets/2.html-CH3Lfqg2.js" as="script"><link rel="prefetch" href="/assets/3.html-BdHsJeXt.js" as="script"><link rel="prefetch" href="/assets/4.html-DMQ4auV-.js" as="script"><link rel="prefetch" href="/assets/5.html-DfN9xCVf.js" as="script"><link rel="prefetch" href="/assets/index.html-WdhsPlA4.js" as="script"><link rel="prefetch" href="/assets/message-board.html-CfmbgH4M.js" as="script"><link rel="prefetch" href="/assets/paper1.html-fV6wB6YA.js" as="script"><link rel="prefetch" href="/assets/1.html-DNAgNDZA.js" as="script"><link rel="prefetch" href="/assets/2.html-C5R4Autn.js" as="script"><link rel="prefetch" href="/assets/3.html-DK6af9JM.js" as="script"><link rel="prefetch" href="/assets/5.html-DPsLJMw7.js" as="script"><link rel="prefetch" href="/assets/graph.html-5CIBCBrB.js" as="script"><link rel="prefetch" href="/assets/offer-java.html-Cta5X4Zq.js" as="script"><link rel="prefetch" href="/assets/offer-java2.html-BIsde5Aw.js" as="script"><link rel="prefetch" href="/assets/offer-java3.html-BWHyTuTk.js" as="script"><link rel="prefetch" href="/assets/paixu.html-CTlhvtwY.js" as="script"><link rel="prefetch" href="/assets/stackandheap.html-CzYar6IN.js" as="script"><link rel="prefetch" href="/assets/tanxin.html-Bd8QFkI8.js" as="script"><link rel="prefetch" href="/assets/union.html-C-rIowYH.js" as="script"><link rel="prefetch" href="/assets/DI.html-BTUBN0Yq.js" as="script"><link rel="prefetch" href="/assets/MVCC.html-lou3MBhW.js" as="script"><link rel="prefetch" href="/assets/mysql.html-BOQ4NhUE.js" as="script"><link rel="prefetch" href="/assets/RDBandAOF.html-_I4G8B7g.js" as="script"><link rel="prefetch" href="/assets/SpringBootStarter.html-DEWEniVA.js" as="script"><link rel="prefetch" href="/assets/xitongshejitu.html-D0H_S4nZ.js" as="script"><link rel="prefetch" href="/assets/yuanma.html-W_MFSUut.js" as="script"><link rel="prefetch" href="/assets/2.html-4MRJZlyG.js" as="script"><link rel="prefetch" href="/assets/1.html-JSBUOibm.js" as="script"><link rel="prefetch" href="/assets/OpenAI2025.html-fELH9QrW.js" as="script"><link rel="prefetch" href="/assets/DDD.html-CeHEEIZG.js" as="script"><link rel="prefetch" href="/assets/docker.html-Cfisb4jT.js" as="script"><link rel="prefetch" href="/assets/1.html-DxAdDHD2.js" as="script"><link rel="prefetch" href="/assets/1.html-DFi3O1D_.js" as="script"><link rel="prefetch" href="/assets/mybatis.html-BRMASDPi.js" as="script"><link rel="prefetch" href="/assets/Netty.html-C-cqc81w.js" as="script"><link rel="prefetch" href="/assets/1.html-BGDrYRAq.js" as="script"><link rel="prefetch" href="/assets/dayingxiao.html-DvQFx-9p.js" as="script"><link rel="prefetch" href="/assets/dayingxiao1.html-DmwAH1zk.js" as="script"><link rel="prefetch" href="/assets/dayingxiao2.html-D1l-P9nb.js" as="script"><link rel="prefetch" href="/assets/dayingxiao3.html-40uKAzj-.js" as="script"><link rel="prefetch" href="/assets/dayingxiao4.html-BZbRh9nA.js" as="script"><link rel="prefetch" href="/assets/mybatis.html-B4ZxjtR7.js" as="script"><link rel="prefetch" href="/assets/IM.html-DirPUTan.js" as="script"><link rel="prefetch" href="/assets/guide.html-6OjT6Zzq.js" as="script"><link rel="prefetch" href="/assets/1.html-CQTYeHei.js" as="script"><link rel="prefetch" href="/assets/2.html-DORNh2MT.js" as="script"><link rel="prefetch" href="/assets/3.html-ClM1MjTW.js" as="script"><link rel="prefetch" href="/assets/4.html-DsFL8_Ty.js" as="script"><link rel="prefetch" href="/assets/4.html-Bwskl05a.js" as="script"><link rel="prefetch" href="/assets/5.html-DyEMkrlQ.js" as="script"><link rel="prefetch" href="/assets/wrench1.html-BZhhs7Bn.js" as="script"><link rel="prefetch" href="/assets/wrench2.html-LDT9UiS9.js" as="script"><link rel="prefetch" href="/assets/wrench3.html-Cu9ImrE_.js" as="script"><link rel="prefetch" href="/assets/404.html-DKeMwnuU.js" as="script"><link rel="prefetch" href="/assets/Valine.min-_LyT3bfY.js" as="script"><link rel="prefetch" href="/assets/giscus-aTimukGI-DWEKOTfS.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container series--no show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/logo1.jpg" alt="orbisz-Blog"><a href="/" class="site-name can-hide">orbisz-Blog</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><a href="/" class="link" aria-label="首页"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconHome class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconHome><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->首页<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/docs/message-board" class="link" aria-label="留言板"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconChat class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconChat><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->留言板<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a class="link" href="https://blog.csdn.net/hywzxy" target="_blank" rel="noopener noreferrer" aria-label="CSDN"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconCSDN class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconCSDN><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->CSDN<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a class="link" href="https://github.com/orbisz" target="_blank" rel="noopener noreferrer" aria-label="Github"><!--[--><!--]--><span class="xicon-container left"><!--[--><IconGithub class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"></IconGithub><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Github<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="项目体验"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->项目体验<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="项目体验"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->项目体验<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a class="link" href="http://117.72.164.204:3000/?userId=zxy&amp;activityId=100301" target="_blank" rel="noopener noreferrer" aria-label="幸运营销汇"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->幸运营销汇<!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a class="link" href="http://101.43.191.204" target="_blank" rel="noopener noreferrer" aria-label="Ai-Agent 智能体 "><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Ai-Agent 智能体 <!--]--></span></span><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--><!----><span class="xicon-container btn-toggle-dark-mode btn--dark-mode navbar-links__item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><ul class="social-links navbar-links__item"><!--[--><!--]--></ul></nav><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><!----><!----><!----><div class="theme-main" style=""><!----><!--[--><main class="page-container"><div class="page-content"><h1 class="page-title">AI Agent 基础了解</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->orbisz<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2025/10/05<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/categories/AI-Agent-xuexirizhi/1.html" class="">AI Agent 学习日志</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M10 14a4 4 0 1 1 4-4a4.005 4.005 0 0 1-4 4zm0-6a2 2 0 1 0 1.998 2.004A2.002 2.002 0 0 0 10 8z" fill="currentColor"></path><path d="M16.644 29.415L2.586 15.354A2 2 0 0 1 2 13.941V4a2 2 0 0 1 2-2h9.941a2 2 0 0 1 1.414.586l14.06 14.058a2 2 0 0 1 0 2.828l-9.943 9.943a2 2 0 0 1-2.829 0zM4 4v9.942L18.058 28L28 18.058L13.942 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/tags/AI/1.html" class="">AI</a><a href="/tags/AI-Agent/1.html" class="">AI Agent</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;font-size:18px;" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 12 12"><g fill="none"><path d="M1.974 6.659a.5.5 0 0 1-.948-.317c-.01.03 0-.001 0-.001a1.633 1.633 0 0 1 .062-.162c.04-.095.099-.226.18-.381c.165-.31.422-.723.801-1.136C2.834 3.827 4.087 3 6 3c1.913 0 3.166.827 3.931 1.662a5.479 5.479 0 0 1 .98 1.517l.046.113c.003.008.013.06.023.11L11 6.5s.084.333-.342.474a.5.5 0 0 1-.632-.314v-.003l-.006-.016a3.678 3.678 0 0 0-.172-.376a4.477 4.477 0 0 0-.654-.927C8.584 4.673 7.587 4 6 4s-2.584.673-3.194 1.338a4.477 4.477 0 0 0-.795 1.225a2.209 2.209 0 0 0-.03.078l-.007.018zM6 5a2 2 0 1 0 0 4a2 2 0 0 0 0-4zM5 7a1 1 0 1 1 2 0a1 1 0 0 1-2 0z" fill="currentColor"></path></g></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><span id="/blogs/AI/1.html" class="leancloud-visitors" data-flag-title="Your Article Title"><a class="leancloud-visitors-count" style=""></a></span><!----><!--]--></span></span></div><div class="theme-reco-md-content"><div><p>通用人工智能（AGI）的终极目标是创造一种能够像人类一样完成各种复杂任务，同时还能自然交流的通用人工智能。根据这个定义，AGI 的发展被分成了五个等级。</p><p>目前使用的大语言模型，比如ChatGPT、DeepSeek等，大多停留在第一级和第二级，可以处理许多知识性的问题，它们的能力主要在于接收指令，根据预训练时学到的知识进行推理并给出答案。 这种工作方式虽然和人类的思考有些相似，但它们在许多需要更高认知能力的任务上仍然力有不逮，比如无法长期记住信息，缺乏持续的记忆能力；面对复杂任务，难以像人类那样分解成具体的步骤并逐步完成，更不用说像人类一样灵活地调用各种工具，并将它们组合起来完成目标。</p><p>AI Agent ，也就是“智能体”，是通向更高级智能的关键一步。通过引入行动能力、长期记忆机制和工具整合能力，AI Agent 能弥补当前大语言模型的短板，使得它们不仅能够回答问题，还可以真正去“做”事情。</p><h2 id="术语概念" tabindex="-1"><a class="header-anchor" href="#术语概念"><span>术语概念</span></a></h2><ul><li>Agent：“代理” 通常是指有意行动的表现。在哲学领域，Agent 可以是人、动物，甚至是具有自主性的概念或实体。</li><li>AI Agent：AI Agent（人工智能代理）是一种能够感知环境、进行决策和执行动作的智能实体。</li><li>RPA：RPA(Robotic Process Automation) 即机器人流程自动化，是一种软件自动化技术。RPA 通过模仿人类在电脑上的手动操作，如打开网站、点击鼠标、键盘输入等，实现业务流程的自动化。 RPA 系统可以自动处理大量重复的、基于规则的工作流程任务，例如在银行中，纸质文件输入、文件票据验证、从电子邮件和文件中提取数据、跨系统数据迁移、自动化 IT 应用操作等。 RPA 的主要优势包括减少劳动成本、提高生产力、出错率低、可监控的操作和开发周期短。它可以在金融、办公自动化、IT 流程自动化等多个领域发挥重要作用。</li><li>Copilot：即飞机的 “副驾驶”，这里 Copilot 指依托于底层大语言模型（LLM），用户只需说几句话，做出指示，它就可以创建类似人类撰写的文本和其他内容。</li><li>LangChain：LangChain 是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序，它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 是一个语言模型集成框架，其使用案例与语言模型的使用案例大致重叠，包括文档分析和摘要、聊天机器人和代码分析。</li><li>LLM：大型语言模型（LLM）是一种人工智能（AI）算法，它使用深度学习技术和大量大型数据集来理解、总结、生成和预测新内容。</li><li>感知记忆（Sensory Memory）：感知记忆是信息处理的第一个阶段，它涉及对通过感官接收的信息进行短暂的存储。感知记忆通常只持续几百毫秒到几秒。就像你看到一张美丽的风景照片，感知记忆是大脑对刚刚通过感官接收到的信息的短暂存储。比如，你闭上眼睛后，还能在脑海中短暂地 “看到” 那张照片的颜色和形状，这就是感知记忆在起作用。</li><li>短期记忆（Short-term memory）：短期记忆就像是你的心智工作台，它能够暂时存储和处理少量信息。比如，当你试图记住一个电话号码时，你可能会重复念叨这个号码，直到你拨打它，这就是短期记忆在工作。所有的上下文学习（In-context Learning）都是利用模型的短期记忆来学习。</li><li>长期记忆（Long-term memory）：长期记忆就像是一个大仓库，能够存储我们的经验、知识和技能，而且这个存储时间可以非常长，甚至是一生。比如，你学会骑自行车的技能，即使多年不骑，你仍然记得怎么骑，这就是长期记忆。Agent 一般通过外部向量存储和快速检索实现。</li><li>Memory Stream：“记忆” 存储了 Agent 过去的观察、思考和行动序列。正如人脑依靠记忆系统来回溯利用先前的经验制定策略和做出决策一样，Agent 也需要特定的记忆机制来确保其熟练处理一系列连续任务。</li><li>MRKL（Modular Reasoning, Knowledge and Language）：MRKL 可以理解为是一种构建 AI 的方式，用于自主代理的神经符号结构，它将推理、知识理解和语言能力作为不同的模块来处理。就像搭积木，每个积木代表 AI 的一个能力，组合在一起就能让 AI 进行复杂的思考和交流。</li><li>TALM（Tool Augmented Language Models）：TOOL 增强的语言模型，是指通过工具或技术来增强的语言处理模型，通常通过微调来实现。 例如，一个 AI 聊天机器人，通过接入搜索引擎或其他数据库，能够更准确地回答问题或提供信息。</li><li>子目标与分解（Subgoal and decomposition）：在解决问题时，Agent 经常会把一个大目标分解成几个小目标（子目标），从而实现对复杂任务的高效处理。比如，准备一顿晚餐，你可能需要先去购物（子目标 1），然后准备食材（子目标 2），最后烹饪（子目标 3）。</li><li>反思与完善（Reflection and refinement）：Agent 可以对历史的动作进行自我批评和自我反思，从错误中吸取教训，并为未来的步骤进行改进，从而提高最终结果的质量。就像写完一篇文章后，你回顾并修改语法错误或不清晰的表达，使文章更加完善。</li><li>思维链（Chain-of-thought, CoT）：已成为一种标准的提示技术，用于提高模型在复杂任务中的表现。模型被要求 “一步一步地思考”，将艰巨的任务分解为更小更简单的步骤。 思维链将大任务转化为多个可管理的任务，并帮助人们理解模型的思维过程。思维链是解决问题时的逻辑推理过程。 比如，你想找出为什么天空是蓝色的，你可能会想：“光是由不同颜色组成的... 蓝色光波短，容易被大气散射... 所以天空看起来是蓝色的。 思维链提示，就是把一个多步骤推理问题，分解成很多个中间步骤，分配给更多的计算量，生成更多的 token，再把这些答案拼接在一起进行求解。</li><li>思维树（Tree of Thoughts, ToT）：通过在任务的每一步探索多种推理可能性来扩展思维链。它首先将问题分解为多个思考步骤，并在每个步骤中生成多个想法，从而创建一个树状结构。 搜索过程可以是 BFS（广度优先搜索）或 DFS（深度优先搜索）。思维树是一种图形化的思维链，它像一棵大树，每个分支代表一个思考的方向或想法，可以帮助我们组织和可视化复杂的思考过程。 ToT 做 4 件事：思想分解、思想生成器、状态评估器和搜索算法。</li><li>自我反思（Self Reflection）： 自我反思是指对自己的行为、想法或情感进行深入的思考和分析。就像在一天结束时，回想自己的所作所为，评估自己做得好的地方和需要改进的地方。</li><li>ReAct：将任务中单独的行为和语言空间组合在一起，从而使大模型的推理和行动融为一体。该模式帮助大模型与环境互动（例如使用维基百科搜索 API），并以自然语言留下推理的痕迹。 主要包括：Thought：Action\Observation。</li><li>Reflexion：一个让 AI Agent 具备动态记忆和自我反思能力以提高推理能力的框架。沿用了 ReAct 中的设置，并提供简单的二进制奖励。 每次行动后，AI Agent 都会计算一个启发式函数，并根据自我反思的结果决定是否重置环境以开始新的试验。这个启发式的函数可以判断是否当下的路径效率低下（耗时过长却没有成功）或包含幻觉（在环境中遇到一连串导致相同观察结果的相同行动），并在出现这两种情况下终止函数。</li><li>Self-ask：Self-ask 可能是指 AI 系统在处理问题时，自主提出问题以引导其思考过程。这类似于人类在面对问题时，会自问：“我接下来应该做什么？” 来推动解决问题的进程。</li><li>后见链（Chain of Hindsight）：通过向模型明确展示一系列过去的输出结果，鼓励模型改进自身的输出结果，使得下一次预测的行动比之前的试验取得更好的成绩。算法蒸馏（Algorithm Distillation）将同样的理念应用于强化学习任务中的跨集轨迹。</li></ul><h3 id="大语言模型" tabindex="-1"><a class="header-anchor" href="#大语言模型"><span>大语言模型</span></a></h3><p>本质上，大语言模型是深层次的 API，核心功能是任务生成。从更高的维度来看，它主要具备以下四大能力：</p><ol><li>文本分类与信息提取：大语言模型能够胜任文本分类任务。例如，当用户输入“我今天想去黄山景区玩”，可以通过模型判断用户的意图。根据输入内容，模型可以识别用户是否想去景区玩、想去哪个景区玩等，这是典型的文本分类任务。</li><li>问答能力（Question-Answering）：问答是大语言模型的经典应用场景。例如，用户提问时，模型能够基于预训练阶段沉淀的知识，通过概率计算生成针对用户问题的适当回答。</li><li>文档总结：大语言模型能够对文档内容进行总结和压缩。例如，用户输入一篇论文，模型可以提取其中的核心观点、使用的方法、数据和验证公式，并生成简明扼要的总结。通过这一功能，模型可以省略与需求无关的内容，将相关信息提炼成简短的表述。</li><li>文本生成：文本生成是大语言模型最核心的能力之一。通过学习前后文字的概率关系，模型可以根据已知内容预测并生成后续文本。例如，在写作任务中，用户提供开头段落，模型能够根据上下文逻辑生成完整的故事情节。这种能力利用了大模型在语料学习中掌握的语言模式和语义关系。</li></ol><h4 id="局限性" tabindex="-1"><a class="header-anchor" href="#局限性"><span>局限性</span></a></h4><ol><li>幻觉问题：大模型在生成内容时可能会产生“幻觉”，即生成一些不存在或错误的信息。例如，当被问到“长颈鹿的腿有几只眼睛”时，早期模型可能会尝试回答一个不真实的问题。 尽管模型对常见的客观事实已有较好的处理，但在私有领域或专业领域，仍可能对非通用共识的内容存在误判。这需要通过模型微调或额外训练，帮助其识别领域内的客观事实。</li><li>指令遵循不稳定：在某些任务中，模型可能无法稳定地遵循指令。例如，当用户要求按照指定格式输出内容时，模型有时会偏离预设格式。这种情况通常通过优化 Prompt（指令）设计和精调来提升模型的指令遵循能力。</li><li>数据的时效性不足：大语言模型的训练数据往往存在滞后性，难以覆盖实时更新的知识。此外，由于预训练耗时长、资源消耗大，无法频繁更新所有知识。 为了解决这一问题，需要通过外挂知识库（RAG）技术，为模型提供实时知识和私有领域知识支持。RAG 通过向量化检索增强模型能力，让其能够回答实时性强、领域专属的问题，从而弥补预训练数据的时效性不足。</li></ol><h2 id="ai-agent" tabindex="-1"><a class="header-anchor" href="#ai-agent"><span>AI Agent</span></a></h2><p>AI Agent（人工智能代理）是一种能够感知环境、进行决策和执行动作的智能实体。 一个基于大模型的 AI Agent 系统可以拆分为大模型、规划、记忆与工具使用四个组件部分。 <img src="/assets/img_1-DeTYGhAB.png" alt="img_1.png"></p><p>AI Agent智能体，通常具备以下特点：</p><ul><li>自主性： AI Agent能够自主决策和执行任务，无需人类干预。</li><li>适应性： 能够根据环境变化调整自己的行为。</li><li>交互性： 能够与人类或其他AI Agent进行交流与合作。</li><li>学习能力： 通过学习不断优化自己的行为和决策</li></ul><h3 id="agents与agentic-workflow的区别" tabindex="-1"><a class="header-anchor" href="#agents与agentic-workflow的区别"><span>Agents与Agentic Workflow的区别</span></a></h3><p>二者的核心差异在于系统架构的自主权分配，直接决定了任务执行的灵活性与适用边界。用戏剧比喻：Workflow是严格遵循剧本的演员，而Agent是自带导演思维的即兴表演者。</p><ul><li><strong>Agentic Workflow（工作流）</strong>：基于预设规则的线性编排，通过硬编码或配置化流程控制LLM与工具的执行顺序 （例如：先调用搜索API获取信息 → 再通过代码工具处理数据 → 最后调用邮件API发送结果）。其决策路径如同火车轨道，所有分支和工具调用在开发阶段已固定。</li><li><strong>Agent（智能体）</strong>：采用动态决策引擎，由LLM自主生成任务分解策略和工具调用序列（例如：面对“帮我策划旅行”的需求，可能自主选择先查天气 → 再比价机票 → 最后生成行程表）。 其决策路径更像GPS导航，根据实时反馈动态调整路线。</li></ul><p><strong>技术实现差异</strong></p><ul><li><strong>Agentic Workflow</strong>：依赖有限状态机（FSM）或低代码平台实现流程编排，开发成本低但扩展性受限。</li><li><strong>Agent</strong>：需要构建认知架构（如MetaGPT中的角色分工、AutoGPT的目标分解），通常结合记忆机制（VectorDB）、工具库（Toolkit）与强化学习实现持续进化。</li></ul><h3 id="ai-agent框架" tabindex="-1"><a class="header-anchor" href="#ai-agent框架"><span>AI agent框架</span></a></h3><h4 id="spring-ai" tabindex="-1"><a class="header-anchor" href="#spring-ai"><span>Spring AI</span></a></h4><p>Spring 官方推出的开源框架（隶属于 Spring 生态系统），专为 Java 开发者设计，用于简化生成式人工智能（如大语言模型 LLM）在企业级应用中的集成与开发。 其核心目标是让开发者能像构建普通 Spring 应用一样便捷地接入和利用 AI 能力，无需深入底层 API 差异。</p><p>它的推出旨在适配当前 AI 潮流，方便开发者集成各类 AI 模型及对应的 API 接口，无需像以往那样为每个模型单独设置。其最主要的优点是：</p><ul><li>内置对文本生成（如 ChatGPT 式对话）、文本嵌入（向量化）、图像生成（如 DALL-E）、语音转文本、内容审核等功能的支持；</li><li>与 Spring Boot 深度集成，极大简化开发流程。</li></ul><p><strong>代码示例：SpringAI 调用 AI 服务</strong></p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre><code><span class="line"><span class="token annotation punctuation">@RestController</span></span>
<span class="line"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">AIController</span> <span class="token punctuation">{</span>    </span>
<span class="line">    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">OpenAiChatClient</span> chatClient<span class="token punctuation">;</span>    </span>
<span class="line">    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">ask</span><span class="token punctuation">(</span><span class="token annotation punctuation">@RequestParam</span> <span class="token class-name">String</span> question<span class="token punctuation">)</span> <span class="token punctuation">{</span>        </span>
<span class="line">        <span class="token keyword">return</span> chatClient<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 一行调用 AI 服务    </span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-alibaba-springai" tabindex="-1"><a class="header-anchor" href="#_2-alibaba-springai"><span>2. Alibaba SpringAI</span></a></h4><p>阿里巴巴的 Spring AI Alibaba 是基于 Spring AI 框架的企业级扩展，由阿里云团队开发，专注于为 Java 开发者提供与阿里云生态深度集成的 AI 应用开发解决方案。</p><p>它与原生 SpringAI 的核心差异在于<strong>本土化适配</strong>，针对国内常用模型做了优化，更适合国内开发人员使用，具体优势包括：</p><ul><li>集成阿里云生态组件：ARMS（应用监控）、Langfuse（可观测性）、Nacos（动态配置管理），实现生产环境的高可用治理；</li><li>国产模型原生支持：默认支持通义千问等国产大模型，并优化中文场景的 Prompt 工程和 RAG（检索增强生成）能力；</li><li>内置 RAG 核心组件：提供 DocumentReader、Splitter、Embedding 等组件，支持海量文档的向量化存储与边界合并。</li></ul><p><strong>代码示例：Alibaba SpringAI 实现模型交互</strong></p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre><code><span class="line"><span class="token comment">// 4行代码实现模型交互</span></span>
<span class="line"><span class="token annotation punctuation">@Autowired</span> </span>
<span class="line"><span class="token keyword">private</span> <span class="token class-name">ChatClient</span> chatClient<span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">ask</span><span class="token punctuation">(</span><span class="token class-name">String</span> question<span class="token punctuation">)</span> <span class="token punctuation">{</span>    </span>
<span class="line">    <span class="token keyword">return</span> chatClient<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getContent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> </span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>核心框架对比</strong></p><table><thead><tr><th>框架</th><th>定位</th><th>核心功能</th><th>优势</th><th>劣势</th><th>典型场景</th></tr></thead><tbody><tr><td>langchain4j</td><td>Java 版 LangChain，简化 LLM 集成</td><td>统一 LLM/向量库 API、Agent 工具链、RAG 流水线、多轮对话管理</td><td>1. Java 生态友好：无缝对接 Spring、Quarkus 等框架<br>2. 异步编程优化：支持大规模数据集处理<br>3. 多语言协作：通过统一 API 兼容 Python/JavaScript 项目</td><td>1. 企业级支持不足：开源社区活跃但缺乏商业级技术支持<br>2. 功能待完善：部分高级功能（如复杂 Agent 决策链）尚未成熟</td><td>聊天机器人、RAG 知识库、多模态交互系统</td></tr><tr><td>spring-ai</td><td>Spring 生态 AI 开发框架，支持微服务架构</td><td>模型加载/预测、数据预处理、分布式训练、硬件加速适配、与 Spring Boot/Cloud 深度集成</td><td>1. 企业级特性：依赖注入、配置管理、监控体系<br>2. 低学习成本：Spring 开发者可快速上手<br>3. 多框架兼容：支持 TensorFlow、PyTorch 等主流库</td><td>1. Java 版本限制：需 Java 17+，不兼容 Java 8<br>2. 模型适配有限：对 LLM 支持较弱，需依赖第三方库</td><td>传统企业 AI 化改造、AI 微服务、数据分析平台</td></tr><tr><td>spring-ai-alibaba</td><td>Spring AI 的阿里云扩展，聚焦云原生开发</td><td>阿里云大模型（如通义千问）集成、Prompt 模板管理、异步任务编排、私有化部署支持</td><td>1. 阿里云深度整合：无缝对接阿里云 OSS、函数计算等服务<br>2. 中文优化：内置中文 NLP 工具包<br>3. 企业级服务：提供商业技术支持和私有化部署方案</td><td>1. 云厂商绑定：对非阿里云环境适配困难<br>2. 功能封闭：部分高级功能需付费解锁</td><td>阿里云用户的 AI 中台建设、企业级智能客服、数据合规场景</td></tr></tbody></table><p><strong>同类产品对比</strong></p><table><thead><tr><th>产品</th><th>核心差异</th><th>适用场景</th><th>对比维度</th></tr></thead><tbody><tr><td>JBoltAI</td><td>收费框架，提供 AIGS 解决方案（智能表单/搜索/对话）、低代码开发平台、私有化部署支持</td><td>企业级数智化转型、复杂业务系统改造</td><td>企业级功能：支持多模态交互、高并发处理，提供商业授权和定制服务</td></tr><tr><td>H2O.ai</td><td>端到端 GenAI 云平台，支持文档分析、自动化数据标注、无代码模型微调</td><td>金融风控、医疗影像分析、大规模数据处理</td><td>全栈能力：涵盖数据预处理、模型训练、部署监控，支持多模态 OCR</td></tr><tr><td>Deeplearning4j</td><td>Java 深度学习框架，支持 CNN/RNN/LSTM 等模型，与 Hadoop/Spark 集成</td><td>图像识别、时间序列预测、推荐系统</td><td>分布式训练：支持 GPU 加速和集群资源管理</td></tr><tr><td>TensorFlow Serving</td><td>专注模型部署，支持多版本管理、灰度发布、GPU 优化，兼容 TensorFlow/PyTorch 模型</td><td>高并发推理服务、边缘计算设备</td><td>高性能推理：内置批处理优化和负载均衡策略</td></tr><tr><td>Kubeflow</td><td>MLOps 平台，基于 Kubernetes 编排 ML 工作流，支持分布式训练、模型服务、实验跟踪</td><td>大规模模型训练、生产级部署流水线</td><td>云原生架构：与 K8s 深度集成，支持混合云/私有化部署</td></tr></tbody></table><p><strong>关键特性横向对比</strong></p><table><thead><tr><th>特性</th><th>langchain4j</th><th>spring-ai</th><th>spring-ai-alibaba</th><th>JBoltAI</th><th>H2O.ai</th></tr></thead><tbody><tr><td>编程语言</td><td>Java</td><td>Java</td><td>Java</td><td>Java</td><td>Python/Scala</td></tr><tr><td>企业级支持</td><td>社区驱动（开源）</td><td>社区驱动（开源）</td><td>阿里云商业支持</td><td>付费授权（企业版）</td><td>云服务订阅</td></tr><tr><td>LLM 支持</td><td>OpenAI、Hugging Face 等 15+ 模型</td><td>需依赖第三方库</td><td>通义千问、LLaMA 等</td><td>国内外主流模型</td><td>自研模型（如 H2O Danube）</td></tr><tr><td>微服务架构</td><td>支持（需集成 Spring）</td><td>原生支持</td><td>原生支持</td><td>支持</td><td>云原生部署</td></tr><tr><td>中文优化</td><td>基础支持</td><td>基础支持</td><td>深度优化（分词/实体识别）</td><td>深度优化</td><td>部分支持</td></tr><tr><td>RAG 能力</td><td>内置工具链</td><td>需自定义实现</td><td>阿里云知识库集成</td><td>可视化配置</td><td>文档分析模块</td></tr><tr><td>部署方式</td><td>JAR 包</td><td>Spring Boot 应用</td><td>阿里云函数计算/容器服务</td><td>私有化套件</td><td>云服务/本地部署</td></tr></tbody></table><h3 id="multi-agent框架" tabindex="-1"><a class="header-anchor" href="#multi-agent框架"><span>Multi-Agent框架</span></a></h3><h4 id="_1-autogen" tabindex="-1"><a class="header-anchor" href="#_1-autogen"><span>1. AutoGen</span></a></h4><p>GitHub:https://github.com/microsoft/autogen</p><p>由微软推出的一个框架，支持创建和管理多个自主Agent，协同完成复杂的任务。这个框架的灵活性极高，可以根据需求定义不同类型的Agent， 包括特定任务的专家、通用助手、策略制定者等。AutoGen提供了一个虚拟的对话空间，让Agent之间可以相互沟通和协作，并支持多方对话和协作， 包括文本、音频或视频形式。</p><h4 id="_2-langgraph" tabindex="-1"><a class="header-anchor" href="#_2-langgraph"><span>2. LangGraph</span></a></h4><p>GitHub:https://github.com/langchain-ai/langgraph</p><p>基于LangChain打造的Multi-Agent框架，通过引入有向循环图的理念，打造了一个极具灵活性和可定制性的解决方案。 LangGraph不仅适用于各类Multi-Agent任务，还能支持几乎所有的多智能体编排应用，使其成为那些面临复杂任务、追求高度灵活性和定制化能力的开发者的首选工具。</p><h4 id="_3-openai-swarm" tabindex="-1"><a class="header-anchor" href="#_3-openai-swarm"><span>3. OpenAI Swarm</span></a></h4><p>GitHub:https://github.com/openai/swarm</p><p>OpenAI推出的一个轻量级多智能体编排框架，致力于简化智能体的构建过程以及智能体间的交接操作（即Handoffs）。 Swarm框架特别适合初学者，让他们能够轻松入门多智能体技术，快速搭建演示项目。Swarm的智能体组件可以配备工具、指令和其他参数来执行特定任务。</p><h4 id="_4-crewai" tabindex="-1"><a class="header-anchor" href="#_4-crewai"><span>4. crewAI</span></a></h4><p>GitHub:https://github.com/crewAIInc/crewAI</p><p>CrewAI推出的高性能多智能体协作框架，专注于复杂任务的分布式协同与动态角色分配。该框架提供直观的API设计，允许开发者通过声明式代码快速定义智能体角色、目标及交互规则，支持链式任务流、异步通信和实时状态监控。 CrewAI强调&quot;以任务为中心&quot;的编排理念，内置任务优先级调度、结果聚合模块，适用于自动化工作流、数据管道和科研计算等场景，助力开发者构建工业级多智能体系统。</p><h3 id="langchain" tabindex="-1"><a class="header-anchor" href="#langchain"><span>LangChain</span></a></h3><p>LangChain 是一个开源框架，专为构建基于大型语言模型（LLM，如 GPT-3/4、Claude、LLaMA 等）的复杂应用程序而设计。 它的核心目标是解决 LLM 应用的两大痛点：如何将 LLM 与外部数据和工具连接，以及如何组织多个 LLM 调用形成复杂工作流。</p><p>可以把 LangChain 理解为 LLM 的“操作系统”——它提供了标准化的接口和模块，让开发者无需从头搭建底层逻辑，就能快速组装出能“思考、记忆、使用工具、连接数据”的智能应用。 LangChain 是一个语言模型集成框架，其使用案例与语言模型的使用案例大致重叠，包括文档分析和摘要、聊天机器人和代码分析。</p><p>LangChain 的核心组件：六大模块</p><ul><li>模型集成（Models）：统一对接各类的LLM和聊天模型，提供标准化调用接口</li><li>提示工程（Prompts）：优化输入给LLM的提示词，提升输出质量</li><li>索引（Indexes）：将非结构化数据（文本、PDF、数据库等）转化为 LLM 能理解的格式，解决 LLM “知识截止”和“数据实时性”问题。</li><li>链（Chains）：将多个 LangChain 组件（模型、提示、索引等）串联起来，形成复杂任务的处理流程。</li><li>记忆（Memory）：解决 LLM “无状态”问题，让应用能记住对话历史、用户偏好等信息。</li><li>代理（Agents）：赋予 LLM “自主思考”能力——当遇到无法直接回答的问题时，LLM 能自主选择调用外部工具（如计算器、搜索引擎、API），并基于工具结果生成答案。</li></ul><h3 id="langgraph" tabindex="-1"><a class="header-anchor" href="#langgraph"><span>LangGraph</span></a></h3><p>LangGraph 是由 LangChain 团队开发的开源 MIT 许可框架，核心定位是为构建有状态管理、多智能体协作能力的复杂 AI 应用提供基础设施， 通过 “图结构（StateGraph）” 组织任务流程，解决传统线性框架（如 LangChain 早期版本）在动态流程控制、长时状态跟踪上的不足， 尤其适配 LLM（大语言模型）驱动的智能体系统开发。</p><table><thead><tr><th>核心概念</th><th>定义与作用</th><th>关键特性</th></tr></thead><tbody><tr><td>State（状态）</td><td>贯穿全流程的“共享数据容器”，存储所有上下文信息（如用户输入、历史对话、工具输出、中间结果等）</td><td>- 通常用 <code>TypedDict</code> 或 <code>Pydantic</code> 定义结构，支持动态字段更新；<br>- 节点执行后会返回更新后的状态，确保上下文不丢失；<br>- 支持持久化（如存数据库 / Redis），实现断点续传。</td></tr><tr><td>Node（节点）</td><td>图中的“任务执行单元”，对应一个具体函数（如调用 LLM、调用工具、人工审核逻辑）</td><td>- 输入：当前状态；<br>- 输出：更新后的部分 / 完整状态；<br>- 可复用：支持调用 LangChain 组件（如文档分割器）或自定义函数。</td></tr><tr><td>Edge（边）</td><td>定义节点间的“流转规则”，控制执行顺序</td><td>- 普通边：无条件跳转（如节点 A 执行完固定走节点 B）；<br>- 条件边：根据状态动态选择下一个节点（如 LLM 输出“需要工具调用”则走工具节点，否则走结果返回节点）。</td></tr></tbody></table><p><strong>AI Agent 是“目标产物”（具备自主能力的智能体），LangChain 和 LangGraph 是“实现工具”（用于构建 AI Agent 的框架）</strong>。</p><table><thead><tr><th>概念</th><th>核心定位</th><th>本质属性</th><th>典型场景</th></tr></thead><tbody><tr><td><strong>AI Agent</strong></td><td>具备“感知环境→决策→行动→反馈”闭环能力的智能体，能自主完成复杂任务</td><td>目标产物（智能系统）</td><td>自动驾驶（感知路况→规划路线→控制车辆）、智能客服（理解问题→调用工具→生成回答）</td></tr><tr><td><strong>LangChain</strong></td><td>集成 LLM、工具、数据等组件的框架，通过“链（Chains）”串联组件，简化 LLM 应用开发</td><td>开发工具（组件集成框架）</td><td>简单 RAG（检索增强生成）、单步骤工具调用（如“查天气+整理结果”）</td></tr><tr><td><strong>LangGraph</strong></td><td>基于“图结构”的流程编排框架，专注于状态管理和复杂流程（循环、分支、多角色协作）</td><td>开发工具（流程编排框架）</td><td>多智能体协作（规划→执行→审核）、迭代任务（代码生成→测试→修改→再测试）</td></tr></tbody></table><h3 id="评估-ai-agent-效果的标准" tabindex="-1"><a class="header-anchor" href="#评估-ai-agent-效果的标准"><span>评估 AI Agent 效果的标准</span></a></h3><ol><li>主观评估：在没有数据和人工标注的情况下，初始阶段可能需要进行主观评估。这包括请专家对 AI 的回答进行人工评分，或者将问题设计成图灵测试，让专家分辨 AI 生成的答案和人类的答案。这种评估方法以人类能力作为基线，但由于涉及人工评分，成本相对较高。</li><li>端到端任务评估：如果有一定的数据，可以基于端到端任务的指标来评估 AI Agent 的性能。例如，在文档智能领域，可以关注 OCR 提取的准确率等具体任务指标。这种方法侧重于任务的具体要求，更注重 AI Agent 在特定领域的表现。</li><li>通用数据集评估：目前常用的是一些通用数据集，如 ALFWorld、HotPotQA 和 HumanEval 等，用于测试 AI Agent 在决策、问答和编程等多个方向的性能。这种方法强调综合性能，但可能无法完全覆盖所有应用场景。</li><li>Benchmark 形式数据集评估：新兴的评估方法包括一些综合多个领域的 Benchmark 形式的数据集，如清华发布的 AgentBench 等。这些数据集跨足多个领域，对 AI Agent 进行全面评测，使评估更具广度。</li><li>工程层面评估：从工程层面考虑，可以评估系统的稳健性，包括平均报错率、与底层 API 交互的次数等。这种评估方法关注 AI Agent 的工程实现，有助于了解系统的鲁棒性和效率。</li><li>系统层面评估：最终还需要考虑整个系统的性能，包括端到端的运行效率、时延、成本等。这可以通过评估相同任务下不同 AI Agent 的迭代次数、交互次数和整体耗时来实现。</li></ol><h4 id="agentbench-llm-的-agent-能力评估标准" tabindex="-1"><a class="header-anchor" href="#agentbench-llm-的-agent-能力评估标准"><span>AgentBench： LLM 的 Agent 能力评估标准，</span></a></h4><p>用来评估 LLM 作为 Agent 在各种真实世界挑战和 8 个不同环境中的能力表现（如推理和决策能力）。这 8 个环境分别是：操作系统、数据库、知识图谱、卡牌对战游戏、家务事、横向思维谜题、网络购物、网页浏览。</p><p>GPT-4 性能遥遥领先，开源模型能力显著弱于闭源模型。研究者选择了 25 种主流的大模型 API 来进行 Agent 能力评估， 涵盖了闭源模型（如 OpenAI 的 GPT-4、 GPT-3.5 等）和开源模型（ LLaMA 2 和 Baichuan 等）。 根据测试结果来看， GPT-4 基本上在所有环境中都占据领先地位，是名副其实的当前大模型能力边界。 闭源模型 Anthropic 的 Claude 以及 OpenAI 的 GPT-3.5 水平相差不大，而常见的一些开源模型 Vicuna、 Dolly 等由于尺寸和闭源模型相差了至少一个数量级，性能评估显著较弱。</p><p>虽然 LLM 能够在自然语言交流等 NLP 上达到基本的类人水平，但在关注行动有效性、上下文长度记忆、多轮对话一致性和代码生成执行等 Agent 重要能力上的表现仍旧相对落后，基于 LLM 的 AI Agent 的发展空间仍具潜力。</p><p>目前 AI Agent 大致可以划分为两大类：</p><ul><li>自主智能体，力图实现复杂流程自动化。当给定自主智能体一个目标时，它们能自行创建任务、完成任务、创建新任务、重新确定任务列表的优先级、完成新的首要任务，并不断重复这个过程，直到完成目标。准确度要求高，因而更需要外部工具辅助减少大模型不确定性的负面影响。</li><li>智能体模拟，力图更加拟人可信。 分为强调情感情商的智能体以及强调交互的智能体，后者往往是在多智能体环境中，可能涌现出超越设计者规划的场景和能力，大模型生成的不确定性反而成为优势，多样性使其有望成为 AIGC 重要组成部分。</li></ul><h3 id="评测的流程" tabindex="-1"><a class="header-anchor" href="#评测的流程"><span>评测的流程</span></a></h3><ol><li>明确评测指标与维度： 首先，需要定义评测的指标和维度。具体来说，就是明确智能体需要提供的主要能力，以及每项能力的评价标准。需要回答的问题是：哪些能力是关键的？回答的好坏如何定义？这一步是评测的基础， 关系到后续数据集的构建与评估。</li><li>构建评测数据集：根据已定义的能力维度，构建与智能体场景相关的数据集。例如，如果智能体主要应用于文旅景区，需要准备一组与景区相关的问答数据（QA 对）作为评测的基础数据集。 这些数据应覆盖智能体的核心功能，确保评测结果具备代表性。</li><li>评测方式：评测可以采用以下两种方式： <ul><li>主观评测：通过人工评估模型的回答质量。人工评测的人员根据模型的回答打标签或评分，判断其是否符合预期。</li><li>自动化评测：利用更强的模型对智能体的回答进行自动化评价。例如，通过一个更高水平的模型来分析回答的正确性和质量。这种方式可以辅助主观评测，提高效率。</li></ul></li><li>生成评测报告：评测结束后，需要生成一份详细的评测报告。报告应包含以下几个方面： <ul><li>模型效果：包括回答的准确性、相关性等核心指标。</li><li>首字耗时（TTFT）：评估模型首次响应时间是否满足用户场景的需求，判断是否在合理范围内。</li></ul></li><li>完成评测后，可以通过评测报告明确智能体的不足之处，例如： <ul><li>哪些案例（bad case）尚未能有效回答用户问题。</li><li>哪些场景下首字耗时偏长，用户体验受到影响。</li></ul></li></ol><p>根据这些问题，针对性地优化智能体，包括调整 Prompt、优化工作流（Workflow）或更新知识库中的数据与知识内容。通过这一评测与优化的闭环机制，可以不断提升智能体的效果，使其在回答质量和响应速度上更加贴合实际需求。</p><h3 id="实际落地过程中的主要挑战" tabindex="-1"><a class="header-anchor" href="#实际落地过程中的主要挑战"><span>实际落地过程中的主要挑战</span></a></h3><ul><li>行业认知与流程重塑：要成功将 AI Agent 应用于某个行业，首先需要对该行业有深入的了解与认知。这包括对行业原有逻辑和流程的深刻理解，以及对行业知识和数据的充分沉淀。 只有在对行业特点和需求有全面掌握的前提下，才能有效地利用 AI Agent 重塑行业流程，真正发挥其价值。</li><li>效果稳定性与响应时间：AI Agent 的效果稳定性和响应速度是影响用户体验的关键因素。 <ul><li>效果稳定性：大语言模型在某些场景下可能表现不够稳定，因此在搭建 AI Agent 时，如何通过工作流（Workflow）提升其稳定性和可控性，成为一个重要目标。</li><li>响应时间：为了保障用户体验，AI Agent 的首次响应时间（TTFT，Time to First Token）必须在合理范围内，避免因回复过慢而影响用户的使用感受。</li></ul></li><li>充分发挥大模型的能力：AI Agent 的落地需要深刻理解大语言模型的优势与不足，并在此基础上制定最佳实践方案。具体而言，需要明确大模型的局限性，并通过优化 Prompt 等方式，充分挖掘和利用其优势。这不仅能提升模型的表现，也能有效规避潜在的问题。</li></ul><h2 id="rag" tabindex="-1"><a class="header-anchor" href="#rag"><span>RAG</span></a></h2><h3 id="rag工作流程" tabindex="-1"><a class="header-anchor" href="#rag工作流程"><span>RAG工作流程</span></a></h3><p>在RAG架构中，向量数据库扮演着关键的角色，它能够存储和管理大量的上下文信息，包括数据模型、业务规则、历史查询示例等。 这些信息被转化为向量形式存储在向量数据库中，通过向量检索技术可以快速准确地获取与用户问题语义相近的上下文。其工作流程框图如下所示： <img src="/assets/img-CR0esgjP.png" alt="img.png"><strong>文档预处理与向量库构建阶段</strong></p><ul><li>非结构化加载器：作为系统的数据入口，通过适配不同文件格式的解析组件，实现对本地多类型文档（.docx/.xlsx/.PDF ）的结构化转换， 提取文本内容并统一输出为纯文本流（TEXT）</li><li>数据切片：基于文本语义与长度约束（如按段落、固定 Token 数）对纯文本（TEXT）进行分段切割， 生成语义相对完整的文本块（CHUNKS） 。核心作用是控制文本单元大小，适配后续向量模型输入限制，同时保留局部语义完整性，为召回精准上下文做准备。</li><li>向量化（EMBEDDING）利用预训练的文本向量模型，将文本块（CHUNKS）转化为高维向量（EMBEDDING） 。通过语义映射，把文本语义转化为向量空间的数值表示， 使后续可基于向量相似度衡量文本关联度。</li><li>向量数据库作为向量的持久化存储与检索引擎，接收并存储文本块向量（EMBEDDING） ，构建索引加速相似性查询。支持基于向量距离（如余弦相似度）的快速检索，为问答阶段提供 “语义召回” 能力。</li></ul><p><strong>问答推理阶段</strong></p><ul><li>问题向量化（EMBEDDING）：对用户输入的自然语言问题，采用与文档切片相同（或兼容）的向量模型，转化为问题向量（EMBEDDING）， 使问题与文档块在同一向量空间具备可比性。</li><li>问题检索：基于向量数据库，通过向量相似度算法，在已构建的文档向量库中检索与 “问题向量” 最匹配的文本块（CHUNKS） ，输出相关段落（CONTEXT）。 本质是语义层面的 “内容召回”，筛选与问题相关的文档上下文。</li><li>提示模板与 Prompt 构建：将用户问题与召回的相关段落（CONTEXT），按照预设的提示工程模板（如 Instruction + Context + Question 格式 ）拼接， 生成符合 LLM 输入要求的 Prompt（提示词 = 问题 + CONTEXT） 。核心是通过模板约束，引导大模型聚焦上下文进行推理。</li><li>LLM 大语言模型推理：大模型接收格式化 Prompt 后，基于预训练知识与上下文信息，执行语义理解、逻辑推理，生成针对用户问题的回答内容。 利用上下文学习（In-context Learning）能力，实现基于私有文档的精准问答。</li></ul><p><strong>数据分块策略</strong></p><ul><li>固定长度切分：按照预设的字符数或token数量（如每块500字）进行硬性划分，这种方式实现简单、易于执行，但由于忽略了文本的语义结构， 可能会在关键语句中间截断，导致信息碎片化，影响检索结果的连贯性。</li><li>滑动窗口切分：通过设置一定比例的重叠区域（例如前一块末尾20%与后一块重叠），有效缓解了语义断裂问题，使相邻数据块保持语义衔接。 然而，该方法会增加数据冗余度，在处理大规模数据时可能占用更多存储空间和计算资源。</li><li>语义切分：依据标点符号、段落结构、标题层级等语义标识进行划分，能够最大程度保留文本完整性，适合处理结构化良好的文档。 但在面对格式不规范或无明显语义边界的数据时，其切分效果会受到影响。</li><li>父子分段模式（B站创新模式）：采用双层嵌套结构设计：上层的父区块（Parent-chunk）以段落、小节等较大文本单元为划分单位，旨在保留丰富的上下文信息， 确保回答具备充足的背景支撑；下层的子区块（Child-chunk）则将父区块进一步细分为句子或短句，用于实现精准的关键词匹配。 系统运行时，首先通过子区块进行细粒度检索，快速定位与查询最相关的数据片段，随后自动调取对应的父区块内容，将精确匹配的子句与完整的上下文信息相结合，从而生成逻辑清晰、内容详实的响应结果。</li></ul><blockquote><p>父子分段模式在问答系统中的准确率提升30%，同时有效减少了因上下文缺失导致的回答偏差问题，为高效的数据检索与知识应用提供了可靠保障。</p></blockquote><p><strong>Embedding 向量化技术</strong></p><p>作为知识库中非常重要的一个核心技术。无论是文本、图像，还是单词，Embedding 的目标都是将这些内容转化为高维向量表示。这种向量表示捕捉了数据的语义信息，便于在向量数据库中存储和检索。</p><p>向量化的过程实际上是将文本、图像或单词作为一个对象，映射到一个由实数表示的固定向量空间中。可以将这个向量空间想象为一个三维空间，通过一定的向量模型计算完成映射。 向量模型需要经过特殊训练，并依赖大量的文本语言和图像语言数据进行训练。训练完成后，可以将对应的字、文本或图像转化为向量空间中的向量。</p><p>模型训练的目的是为了让语义相似的对象在向量空间中的距离尽可能接近。例如，“king”和“queen”，“man”和“woman”之间存在相似性关系，可以通过向量运算表达。 例如，“woman”可以通过“man + queen - king”得出。这表示“man”和“woman”语义相近，因此它们在向量空间中的距离也较近。 “king”和“queen”同样因语义相似，在空间中的距离更短，而“queen”和“woman”之间的相似性也会导致它们距离较近。</p><p>可以理解为，将具体的文字或图像投射到向量空间后，通过模型的训练，使得语义相似的内容在向量空间中的距离更近，从而实现语义召回，检索出相似的内容。　 对于图像也是类似的。</p><p>在实际应用中，向量化过程会计算两个实体在向量空间的距离，以表示它们之间的相似度。 例如，用户询问“北京大兴机场怎么去”，数据库中可能存有“大兴机场的路线”相关知识。此时，用户问题中的“大兴机场”与数据库中的“大兴机场的路线”在向量空间的距离会较近， 因此可以通过相似度计算将相关知识召回。根据相似度距离排序，检索出与用户 Query 相关的知识，并通过大模型整合后，生成完整的回答。</p><p><strong>工作流</strong></p><p>AI Agent 的运行需要输入一个 Prompt，结合外挂知识库，让 RAG 调用具体工具来连接现实场景和用户需求。然而，为了确保整个执行流程的可靠性和可控性，工作流的能力显得尤为重要。</p><p>通过工作流，我们可以将 AI Agent 的业务流程通过编排的方式串联起来，使其具备计划性和执行的可控性。目前在我自己的项目中也实现了自由编排组装 Agent 的能力。用户可以自由定义 Agent 的执行流程以及自由选取调用工具与知识库。 通过这种方式，将复杂任务拆解为各个节点并逐步串联，实现任务的清晰、流畅且可控的执行。让用户能够个性化地设计和控制任务执行的逻辑，确保每一步操作都符合预期，为复杂任务的高效执行提供了可靠保障。</p><h3 id="rag架构分类" tabindex="-1"><a class="header-anchor" href="#rag架构分类"><span>RAG架构分类</span></a></h3><ul><li>Naive RAG：即RAG的基础实现。它适用于简单的问答场景，但在检索质量和上下文处理方面存在局限。</li><li>Advanced RAG：这种范式在检索前后引入了处理步骤以提升质量。关键策略包括： <ul><li>检索前处理：采用更复杂的文本分块策略、查询转换（如 StepBack-prompting）等优化检索输入。</li><li>检索后处理：对检索到的文档进行 Re-ranking 以提升相关性，并对上下文进行 Compression。</li></ul></li><li>Modular RAG：一种更灵活、更面向系统的 RAG 视图，其中不同的组件（如搜索、检索、记忆、路由）被视为可互换的模块。这使得构建更复杂、更定制化的流程成为可能。具体模式包括： <ul><li>带记忆的 RAG：融合对话历史，以处理多轮交互，使对话更具连续性。</li><li>分支/路由 RAG：引入一个路由模块，根据查询的意图决定使用哪个数据源或检索器。</li><li>Corrective RAG, CRAG：增加了一个自我反思步骤。一个轻量级的评估器会对检索到的文档质量进行打分。如果文档不相关，系统会触发替代的检索策略（如网络搜索）来增强或替换初始结果。</li><li>Self-RAG：让 LLM 自身学习判断何时需要检索以及检索什么内容，通过生成特殊的检索 Token 来自主触发检索。</li><li>Agentic RAG：这是 RAG 最先进的形式，将 RAG 集成到一个智能体循环（agentic loop）中。模型能够执行多步骤任务，主动与多个数据源和工具交互，并随时间推移综合信息。这是 Context Engineering 在实践中的顶峰。</li></ul></li></ul><h3 id="高级-rag-探究" tabindex="-1"><a class="header-anchor" href="#高级-rag-探究"><span>高级 RAG 探究</span></a></h3><p>在初级 RAG 的基础上，高级 RAG 为整个过程引入了一层较为复杂的处理层，以优化回复的相关性和整体质量</p><h4 id="索引优化" tabindex="-1"><a class="header-anchor" href="#索引优化"><span>索引优化</span></a></h4><p>在数据库中，索引方法在高效组织和检索数据方面起着重要作用。广泛采用的传统的索引方法有 B tree 和 Hash 索引等。然而，这些算法的搜索速度随着数据规模的增加而降低。 因此，需要更高效的索引方法来处理更大规模的数据集，比如自研的 MSTG 多尺度树图向量索引算法。该算法在速度和性能方面优于其他索引方法。</p><p>与 HNSW 等流行算法仅依赖于分层图和倒排文件索引（IVF）的两级树结构不同，MSTG 在设计中结合了分层图和树结构的优点。 通常，图算法对于未经过滤的搜索更快，但对于经过过滤的搜索可能不高效。另一方面，树算法在经过过滤的搜索方面表现出色，但对于未经过过滤的搜索速度较慢。 通过结合这两种方法，MSTG 确保了未经过滤和经过过滤的搜索的高性能和准确性，使其成为各种搜索场景的强大选择。</p><p>MSTG（Multi-Scale Tree Graph）核心思想是通过多尺度分层聚类和树图混合结构，结合传统树算法与图算法的优势，在保证精度的同时显著降低资源消耗。</p><ol><li>多尺度分层聚类 <ul><li>分层架构：MSTG 采用树状层级设计，将数据集划分为多层聚类。 <ul><li>顶层：粗粒度聚类（如 100 个簇），快速定位候选区域。</li><li>中间层：中等粒度聚类（如 1,000 个簇），细化搜索范围。</li><li>底层：细粒度聚类（如 10,000 个簇），精确匹配目标。</li></ul></li><li>质心压缩：每层仅存储聚类质心（Centroid），而非所有向量。</li></ul></li><li>树图混合结构 <ul><li>树结构：基于聚类质心构建树形索引，支持快速范围查询。例如，通过二分法在树中定位目标簇，避免全量扫描。</li><li>图结构：在底层聚类中引入图连接，节点间通过相似度边关联。例如，每个节点连接到其 k 近邻节点，形成局部导航图，加速邻域搜索。</li><li>动态切换：根据搜索条件（如过滤比例）自动选择树或图路径。例如，高过滤比例时优先使用树结构，低过滤比例时切换至图结构。</li></ul></li><li>向量化计算优化 <ul><li>SIMD 指令加速：在距离计算中利用 SIMD（单指令多数据）并行处理向量维度，提升计算吞吐量。</li><li>量化压缩：对向量进行 8-bit 或 4-bit 量化，减少内存占用并加速相似度计算。</li></ul></li></ol><h4 id="高级分块策略" tabindex="-1"><a class="header-anchor" href="#高级分块策略"><span>高级分块策略</span></a></h4><ul><li>朴素分块的问题：固定大小的分块方法虽然简单，但常常会粗暴地切断句子或段落，导致上下文支离破碎，语义不完整。</li><li>内容感知分块： <ul><li>递归字符分割：一种更智能的方法，它会按照一个预设的分割符层次结构（如：先按段落，再按句子，最后按单词）进行分割，以尽可能保持文本的自然结构。</li><li>文档特定分块：利用文档自身的结构进行分割，例如，根据 Markdown 的标题、代码文件的函数或法律合同的条款来划分。</li><li>语言学分块：使用 NLTK、spaCy 等自然语言处理库，基于句子、名词短语或动词短语等语法边界进行分割。</li></ul></li><li>语义分块： 这是最先进的方法之一。它使用嵌入模型来检测文本中语义的转变点。当文本的主题或意义发生变化时，就在该处进行分割，从而确保每个分块在主题上是高度内聚的。研究表明，这种策略的性能优于其他方法。</li><li>智能体分块：一个前沿概念，即利用一个 LLM 智能体来决定如何对文本进行分块，例如，通过将文本分解为一系列独立的 propositions 来实现。</li></ul><h4 id="查询重写" tabindex="-1"><a class="header-anchor" href="#查询重写"><span>查询重写</span></a></h4><p>在检索过程开始之前，原始的用户查询经过多次增强以提高准确性和相关性，通常会采用查询重写、扩展和转换等技术。这一步确保检索系统获取最相关的信息。 例如，如果用户的查询过于宽泛，查询重写可以通过添加更多的上下文或特定术语来改进查询，而查询扩展可能会添加同义词或相关术语以涵盖更广泛的相关文档范围。</p><h4 id="动态嵌入" tabindex="-1"><a class="header-anchor" href="#动态嵌入"><span>动态嵌入</span></a></h4><p>在初级 RAG 中，可能会对所有类型的数据使用单个嵌入模型生成固定向量，这可能导致效率低下。 然而，高级 RAG 中使用动态嵌入根据上下文或任务需求动态调整向量表示。 这意味着嵌入模型经过训练或调整，能更灵活地捕捉语义变化，适应多义性、时效性数据及个性化需求。 同时，动态嵌入使大语言模型能够理解细微差别，消除歧义，进而产生更连贯、更相关的回答。</p><h4 id="混合检索" tabindex="-1"><a class="header-anchor" href="#混合检索"><span>混合检索</span></a></h4><p>高级 RAG 还会利用混合搜索，结合不同的搜索策略来提高检索性能，一般包括基于关键字的搜索、语义搜索和神经搜索的不同组合方式。 例如，我们的 AI 数据库支持过滤向量搜索和全文搜索，且可以使用复杂的 SQL 查询。 这种混合方法通过将不同检索技术结合，能弥补各自的不足，发挥各自优势，适应更广泛的复杂检索场景， 提高检索的精准度和语义相关性，提升大模型在复杂检索任务中的表现。</p><h4 id="重新排序" tabindex="-1"><a class="header-anchor" href="#重新排序"><span>重新排序</span></a></h4><p>为了平衡检索的速度和准确性，业界普遍采用两阶段检索流程</p><ul><li>两阶段流程 <ul><li>第一阶段（召回）： 使用一个快速、高效的检索器（如基于 bi-encoder 的向量搜索或 BM25 等词法搜索）进行广泛撒网，召回一个较大的候选文档集（例如，前 100 个）。</li><li>第二阶段（精排/重排序）： 使用一个更强大但计算成本更高的模型，对这个较小的候选集进行重新评估，以识别出最相关的少数几个文档（例如，前 5 个）。</li></ul></li><li>Cross-Encoder： 交叉编码器之所以在重排序阶段表现优越，是因为它与双编码器的工作方式不同。双编码器独立地为查询和文档生成嵌入向量，然后计算它们的相似度。 而交叉编码器则是将查询和文档同时作为输入，让模型在内部通过 Attention Mechanism 对二者进行深度交互。这使得模型能够捕捉到更细微的语义关系，从而给出更准确的相关性评分。</li></ul><p>重排序显著提高了最终送入 LLM 的上下文质量，从而产出更准确、幻觉更少的答案。在金融、法律等高风险领域，重排序被认为是必不可少而非可选的步骤。</p><table><thead><tr><th>对比维度</th><th>初级 RAG</th><th>高级 RAG</th></tr></thead><tbody><tr><td>检索策略</td><td>单向量检索（基于语义相似度），仅依赖向量数据库匹配前K个相似块。</td><td>混合检索（向量检索+关键词检索如 BM25），结合语义与关键词匹配，召回率提升 30%+。</td></tr><tr><td>索引结构</td><td>单一固定块大小（如 500 - 1000 字符），无/仅基础元数据，索引结构简单。</td><td>动态块大小+多索引策略，支持细粒度拆分（段落/句子级），含丰富元数据（日期、章节等）。</td></tr><tr><td>查询处理</td><td>直接用原始查询检索，无优化。</td><td>含“查询改写（口语转专业表述）”“查询扩展（生成问题变体）”等预处理。</td></tr><tr><td>后检索优化</td><td>无后处理，直接传前K个块给 LLM。</td><td>重排序（二次筛选最相关块）+ 上下文压缩（提炼关键信息，减少冗余）。</td></tr><tr><td>领域适应性</td><td>通用场景适用，专业领域（法律、医疗）罕见术语匹配弱。</td><td>支持嵌入模型微调，适配特定领域术语/语境，提升专业场景准确性。</td></tr><tr><td>多轮对话支持</td><td>难关联历史对话，易上下文断裂。</td><td>整合对话历史，动态调整检索策略，保障多轮回复连贯性。</td></tr><tr><td>抗“幻觉”能力</td><td>较弱，检索不准时 LLM 易生成无依据内容。</td><td>较强，通过精准检索+信息校验，减少无根据生成。</td></tr><tr><td>典型应用场景</td><td>简单知识库问答（如产品手册查询）、低精度闲聊辅助。</td><td>金融投顾、法律检索、医疗咨询等高精准场景，及多轮复杂任务处理。</td></tr></tbody></table><h3 id="b站利用rag结合llm实现快速获取数据" tabindex="-1"><a class="header-anchor" href="#b站利用rag结合llm实现快速获取数据"><span>B站利用RAG结合LLM实现快速获取数据</span></a></h3><p><strong>待解决的挑战与展望</strong></p><ul><li>向量检索过程需要在海量的向量数据库中进行相似度计算，随着业务数据量的不断增长以及知识库规模的持续扩大，检索耗时也随之增加。</li><li>大模型在生成SQL时，由于其本身的计算复杂度较高，同样会消耗大量的时间。例如在处理复杂查询时，系统从接收到用户问题到返回SQL语句，有时需要数秒甚至更长时间，这对于追求实时性的数据查询场景来说，用户体验会受到较大影响。</li><li>在迭代测试方面，由于涉及到自然语言理解、SQL生成等多个环节，每个环节都是非幂等性过程，其中任何一个环节的变动都可能影响到最终结果的准确性和可靠性。</li></ul><p><strong>优化</strong></p><ul><li>在向量检索环节，我们将探索更高效的向量索引算法，同时，对向量数据库进行合理的分片和缓存策略设计，减少不必要的检索开销。</li><li>对于大模型生成SQL部分，我们考虑采用模型蒸馏、量化等技术，在不显著降低模型性能的基础上，减小模型的计算量和存储需求，从而加快推理速度。</li><li>建立了半自动化测试工作流，通过后台收集用户Query，然后通过API请求生成测试结果，最后人工对测试报告进行review，评估是否满足上线要求， 不过该方案的缺点就是耗费人力。因此我们计划引入AI Agent，对测试报告进行全面的review，最后人工抽样对Agent生成的结果做二次校验。</li></ul><h3 id="agentic-rag-智能体驱动型rag" tabindex="-1"><a class="header-anchor" href="#agentic-rag-智能体驱动型rag"><span>Agentic RAG（智能体驱动型RAG）</span></a></h3><p>传统RAG的核心优势在于线性无分支的”检索-生成’流程，整个链路清晰可控，能以较低的成本落地。与传统RAG的“线性单项流程”不同，Agentic RAG的核心创新在于引入了“智能体”模块，赋予了LLM自主思考、规划和执行的能力。 让RAG系统从“被动响应”升级为“主动解决问题”，关键特征体现在循环迭代、动态决策和多工具调用方面。</p><p><strong>Agentic RAG工作流程</strong></p><ol><li>智能体预处理：优化查询与初步判断。在用户输入查询后，现有LLM Agent进行处理，对模糊或者冗长的查询进行重写优化（例如将“怎么提升公司业绩”改写为“2024年中小制造业企业提升营收的3个核心策略，需要包含成本控制和市场拓展维度”）， 更符合检索需求，随后智能体进行自我评估，判断当前查询是否需要补充外部信息（“调用行业报告数据库”。“实时搜索最新政策”）。</li><li>动态规划：工具选择与调用，若需补充信息，智能体思考并选择工具（不仅限于向量数据库，还包括搜索引擎、SQL 数据库、第三方 API 等）。例如查询 “实时天气对农产品价格的影响” 时，会调用天气 API 和农产品价格数据库做关联分析。</li><li>检索整合与初步生成：收集工具调用结果，整理为结构化上下文，结合重写后的查询生成提示词，输入 LLM 生成初步回答。</li><li>循环迭代：自我评估与修正，初步回答生成后，智能体二次评估（是否覆盖需求、有无冲突漏洞等）；若不通过，回到前序环节重新规划（如换工具、优化查询再检索），直到生成最终回答。“评估 - 修正” 循环是其解决复杂问题的核心。</li></ol><table><thead><tr><th>对比维度</th><th>传统 RAG</th><th>Agentic RAG</th></tr></thead><tbody><tr><td>LLM 定位</td><td>被动的“内容生成器”，仅负责基于检索结果生成回答</td><td>主动的“智能决策者”，主导查询优化、工具选择、评估修正全流程</td></tr><tr><td>流程结构</td><td>线性单向流程（查询→编码→检索→生成），无循环</td><td>循环迭代流程（查询→规划→检索→生成→评估→修正），含多个决策节点</td></tr><tr><td>工具支持</td><td>仅依赖向量数据库，工具类型单一</td><td>支持多类型工具调用（向量数据库、搜索引擎、API、结构化数据库等）</td></tr><tr><td>复杂需求处理</td><td>无法应对多跳、需推理的复杂需求，仅适用于简单问答</td><td>擅长处理多步推理、跨数据源整合的复杂需求</td></tr><tr><td>自我评估能力</td><td>无评估环节，检索结果直接决定生成质量</td><td>具备自我评估能力，可判断回答相关性、完整性，主动修正偏差</td></tr><tr><td>错误传导风险</td><td>检索错误会直接传递到生成环节，无法修正</td><td>可通过评估和迭代阻断错误传导，降低“幻觉”概率</td></tr><tr><td>落地成本</td><td>开发难度低、资源消耗少，适合快速上线</td><td>开发难度高、需对接多工具，适合复杂场景的深度应用</td></tr></tbody></table><p>传统 RAG 是 “基石”，因简洁高效，在简单问答、固定知识库查询、低延迟场景（如产品说明书问答、内部文档检索）仍不可替代，是企业入门首选。 Agentic RAG 是 “进阶方向”，通过 “智能体思维” 突破传统 RAG 边界，更适合复杂决策、跨数据源整合、高准确性场景（如金融分析、科研综述、企业战略规划）。 实际应用中两者非 “非此即彼”：企业可按需选择（简单需求用传统 RAG 控成本，复杂需求用 Agentic RAG 提能力），甚至构建 “混合架构”，让智能体按查询类型自动切换流程，平衡效率与能力。 随着 LLM 能力和工具生态完善，Agentic RAG 会在更多高阶场景落地，成为构建 “强知识、高可靠、高自主”AI 系统的核心技术之一。</p><h2 id="prompt-and-context" tabindex="-1"><a class="header-anchor" href="#prompt-and-context"><span>Prompt and Context</span></a></h2><p><strong>定义</strong></p><p>一个提示（Prompt）远不止一个简单的问题，它是一个结构化的输入，可包含多个组成部分。这些组件共同构成了与模型沟通的完整指令：</p><ul><li>指令（Instructions）：对模型的核心任务指令，明确告知模型需要执行什么操作。</li><li>主要内容/输入数据（Primary Content/Input Data）：模型需要处理的文本或数据，是分析、转换或生成任务的对象。</li><li>示例（Examples/Shots）：演示期望的输入-输出行为，为模型提供“上下文学习”（In-Context Learning）的基础。</li><li>线索/输出指示器（Cues/Output Indicators）：启动模型输出的引导性词语，或对输出格式（如JSON、Markdown）的明确要求。</li><li>支持性内容（Supporting Content/Context）：为模型提供的额外背景信息，帮助其更好地理解任务情境。正是这一组件，构成了 Context Engineering 发展的概念萌芽。</li></ul><p>随着大语言模型的出现，针对 Prompt 的设计与优化逐渐发展为一个垂直领域，并衍生出一个专门的岗位——Prompt Engineer。 这一领域的重点在于研究如何为不同的大语言模型设计最佳的 Prompt 格式，使模型的回答效果达到最优。</p><h3 id="优质提示词原则" tabindex="-1"><a class="header-anchor" href="#优质提示词原则"><span>优质提示词原则</span></a></h3><ul><li>清晰的指令</li><li>提供上下文和例子</li><li>善用符号与语法</li><li>让模型一步一步的思考</li><li>激励模型反思和给出思路</li><li>给容错空间</li><li>让模型给出信息来源</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">### 角色:</span>
<span class="line">你是一名资深资深的Java高级开发工程师，精通Java 8的集合操作和流式处理，擅长处理空指针和边界情况的防护。</span>
<span class="line"></span>
<span class="line">### 背景说明:</span>
<span class="line">我目前有一批店铺对象`List&lt;ShopModel&gt;`，每个`ShopModel`对象包含字段`shopId`（店铺ID）和`shopName`（店铺名称）。我希望将这批店铺对象转换为`Map&lt;String, String&gt;`，其中键（key）为`shopId`，值（value）为`shopName`。在处理过程中，我希望确保代码健壮且无空指针异常</span>
<span class="line"></span>
<span class="line">### 任务:</span>
<span class="line">请帮我编写一个Java方法，满足以下要求:</span>
<span class="line">1. 方法输入为`List&lt;ShopModel&gt;`，输出为`Map&lt;String, String&gt;`。</span>
<span class="line">2. 如果输入的`List&lt;ShopModel&gt;`为空或为`null`，返回空的`Map`对象。</span>
<span class="line">3. 如果`List&lt;ShopModel&gt;`中包含`null`对象，跳过该对象，不做处理。</span>
<span class="line">4. 使用Java 8流式处理，确保代码简洁、可读性强，并处理好所有空指针异常情况。</span>
<span class="line"></span>
<span class="line">### 输出格式:</span>
<span class="line">直接提供Java代码，包含注释说明。请同时提供一个简单的示例或单元测试代码，展示如何使用这个方法。这条消息已经在编辑器中准备就绪。你想如何调整这篇文档?请随时告诉我。</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>不同模型在Prompt细节上可能存在差异，因此需要结合模型的特点调整设计</p></blockquote><p>除了 Prompt 的结构设计外，还可以通过特定的思维模式让大语言模型遵循更具体的指令，进而优化任务的执行过程。</p><ul><li>思维链（Chain of Thought, CoT）： CoT 是一种引导模型按照逻辑链条逐步完成任务的思维模式。通过 CoT，模型能够将复杂的任务拆解为多个子任务，并对每个子任务的可执行性进行验证。这种模式确保了模型在解决问题时能够逻辑清晰，并对任务有更强的理解和执行能力。</li><li>反应式行动（ReAct）： ReAct 是另一种思维模式，适用于让模型面对复杂问题时将其分解为具体的行动步骤。模型可以基于问题拆分出每个行动（Action），观察每个行动执行的结果，并根据结果确定下一步要执行的任务。通过这种模式，模型能够自主完成任务拆分，并有效执行外部任务，增强其对复杂问题的处理能力。</li></ul><h3 id="prompt-engineering-的核心技术" tabindex="-1"><a class="header-anchor" href="#prompt-engineering-的核心技术"><span>Prompt Engineering 的核心技术</span></a></h3><ul><li>零样本提示（Zero-Shot Prompting）：在不提供任何示例的情况下直接向模型下达任务，完全依赖其在预训练阶段获得的知识和推理能力。</li><li>少样本提示（Few-Shot Prompting）：在提示中提供少量（通常为 1 到 5 个）高质量的示例，以引导模型的行为。对于复杂任务，这种“上下文学习”方法被证明极为有效。</li><li>思维链提示（Chain-of-Thought Prompting, CoT）：引导模型将复杂问题分解为一系列中间推理步骤，显著增强了其在逻辑、数学和推理任务上的表现。</li><li>高级推理技术： 在 CoT 的基础上，研究人员还开发了更为复杂的变体，如思维树（Tree-of-Thought）、苏格拉底式提示（Maieutic Prompting）和由简到繁提示（Least-to-Most Prompting），以探索更多样化的解决方案路径。</li></ul><p><strong>Prompt Engineering 对于构建稳健、可用于生产环境的系统而言，存在固有的局限性</strong></p><ul><li>脆弱性&amp;不可复现性：提示中微小的措辞变化可能导致输出结果的巨大差异，使得这一过程更像是一种依赖反复试错的“艺术”，而非可复现的“科学”。</li><li>扩展性差：手动、迭代地优化提示的过程，在面对大量用户、多样化用例和不断出现的边缘情况时，难以有效扩展。</li><li>用户负担：这种方法将精心构建一套详尽指令的负担完全压在了用户身上，对于需要自主运行、或处理高并发请求的系统而言是不切实际的。</li><li>无状态性：Prompt Engineering 本质上是为单轮、“一次性”的交互而设计的，难以处理需要记忆和状态管理的长对话或多步骤任务。</li></ul><h3 id="context-engineering" tabindex="-1"><a class="header-anchor" href="#context-engineering"><span>Context Engineering</span></a></h3><p>Context Engineering是一门设计、构建并优化动态自动化系统的学科，旨在为大型语言模型在正确的时间、以正确的格式，提供正确的信息和工具，从而可靠、可扩展的完成复杂任务。 其并非要取代 Prompt Engineering，而是一个更高阶、更侧重于系统设计的必要学科。prompt 告诉模型如何思考，而 Context 则赋予模型完成工作所需的知识和工具。</p><p>“Context”涵盖了LLM在做出响应前所能看到的索引信息生态系统：</p><ul><li>系统级指令和角色设定</li><li>对话历史（短期记忆）</li><li>持久化的用户偏好和事实（长期记忆）</li><li>动态检索的外部数据（例如来自RAG）。</li><li>可用的工具（API、函数）及其定义</li><li>期望的输出格式（JSON等）</li></ul><p>Prompt Engineering 是 Context Engineering 的一个子集。</p><ul><li>Context Engineering 决定用什么内容填充 Context Window，</li><li>Prompt Engineering 则负责优化窗口内的具体指令。</li></ul><h4 id="context-engineering-的基石-rag" tabindex="-1"><a class="header-anchor" href="#context-engineering-的基石-rag"><span>Context Engineering 的基石：RAG</span></a></h4><p>检索增强生成（RAG）作为实现 Context Engineering 的主要架构模式。</p><p>组织在选择向量数据库时必须考虑以下主要因素：</p><ul><li>模型：选择完全托管的云服务（如 Pinecone），还是可自托管的开源方案（如 Milvus、Weaviate）。</li><li>扩展性：是否能处理数十亿级别的向量数据和高查询负载（Milvus）。</li><li>功能集： 是否支持混合搜索（关键词+向量）、高级 meta 过滤以及多模态数据处理（Weaviate）。</li><li>易用性与灵活性：是倾向于API简单、设置最少的方案（Pinecone），还是需要多种索引算法和深度配置选项的方案（Milvus）。</li></ul><p><img src="/assets/img_3-DXq9SQv9.png" alt="img_3.png"></p><h4 id="核心问题-lost-in-the-middle" tabindex="-1"><a class="header-anchor" href="#核心问题-lost-in-the-middle"><span>核心问题 - Lost in the Middle</span></a></h4><p>当前LLM存在一个根本性认知局限，这一局限使得简单的上下文堆砌变得无效，并催生了后续的优化技术。</p><ul><li>定义：LLM 在处理长上下文时表现出一种独特的 U 型 性能曲线。当关键信息位于上下文窗口的开头（首因效应）或结尾（近因效应）时，模型能够高效地利用这些信息。然而，当关键信息被 “hidden”在长篇上下文的中间位置时，模型的性能会显著下降。</li><li>实验： 在多文档问答任务时，即使检索器召回了更多相关的文档，模型的性能提升也很快达到饱和。这意味着简单地增加上下文长度（即添加更多文档）不仅无益，甚至因为关键信息被淹没而损害性能。</li><li>“知道但说不出来”： 并非模型“找不到”信息。通过探测模型的内部表征发现，模型通常能够准确地编码关键信息的位置，但在生成最终答案时却未能有效利用这些信息。这表明在模型内部，信息检索和信息利用（或沟通）之间存在脱节。</li></ul><p><img src="/assets/img_4-BBeRitu5.png" alt="img_4.png"></p><h3 id="上下文丰富性与窗口局限性之间的考量" tabindex="-1"><a class="header-anchor" href="#上下文丰富性与窗口局限性之间的考量"><span>上下文丰富性与窗口局限性之间的考量</span></a></h3><p>一方面，提供丰富、全面的上下文是获得高质量响应的关键。另一方面，LLM 的上下文窗口是有限的，并且由于 Lost in the Middle、contextual distraction 等问题，过长的上下文反而会导致性能下降。</p><p>因此产生了一个核心的优化问题：如何在固定的Token预算内，最大化“信号”（真正相关的信息），同时最小化“噪声”（不相关或分散注意力的信息），并充分考虑到模型存在的认知偏差？</p><p>Context Engineering 领域所有的高级技术——无论是语义分块、重排序，还是后续将讨论的压缩、摘要和智能体隔离——都是为了有效管理这一权衡而设计的。 因此，Context Engineering 不仅是关于提供上下文，更是关于如何策划和塑造上下文，使其对一个认知能力有限的处理单元（LLM）最为有效。</p><h4 id="优化上下文窗口-压缩与摘要" tabindex="-1"><a class="header-anchor" href="#优化上下文窗口-压缩与摘要"><span>优化上下文窗口：压缩与摘要</span></a></h4><p>缩短检索到的文档列表/精简单个文档的内容，只讲关键信息传递给LLM。这样能有效降低API调用成本、减少延迟，并缓解Lost in the Middle的问题。</p><p><strong>压缩方法</strong></p><ul><li>过滤式压缩：决定是保留还是丢弃整个检索到的文档</li><li>LLMChainFilter：利用一个 LLM 对每个文档的相关性做出简单的“是/否”判断。</li><li>EmbeddingsFilter：更经济快速的方法，根据文档嵌入与查询嵌入的余弦相似度来过滤文档。</li><li>内容提取式压缩：直接修改文档内容</li><li>LLMChainExtractor：遍历每个文档，并使用 LLM 从中提取仅与查询相关的句子或陈述。</li><li>用TOP N代替压缩：像 LLMListwiseRerank 这样的技术，使用 LLM 对检索到的文档进行重排序，并只返回排名最高的 N 个，从而起到高质量过滤器的作用。</li></ul><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ol><li><a href="https://xie.infoq.cn/article/b31ea85ab23da511c54a98317" target="_blank" rel="noopener noreferrer">万字长文解析 AI Agent 技术原理和应用<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 华为云开发者联盟</li><li><a href="https://mp.weixin.qq.com/s/itFAEndoQu28QWoD7TVmcw?scene=1" target="_blank" rel="noopener noreferrer">RAG在B站大会员中心数据智能平台的应用实践<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 哔哩哔哩技术</li><li><a href="https://cloud.tencent.com/developer/article/2536641?policyId=1003" target="_blank" rel="noopener noreferrer">智能体框架：11 个顶级 AI Agent 框架！<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://zhuanlan.zhihu.com/p/21147735813" target="_blank" rel="noopener noreferrer">2025年，AI Agent干货资料、论文综述都在这了<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 大语言模型论文</li><li><a href="https://zhuanlan.zhihu.com/p/676245844" target="_blank" rel="noopener noreferrer">AI Agent行业深度：框架拆解、应用方向、应用领域及相关公司深度梳理<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 慧博智能投研</li><li><a href="https://cloud.tencent.com/developer/article/2485515" target="_blank" rel="noopener noreferrer">最新AI Agent万字综述分享！<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 王月凡，支付宝百宝箱团队</li><li><a href="https://mp.weixin.qq.com/s/pIcZPDqYzXrE3i6Zh4sr-Q" target="_blank" rel="noopener noreferrer">Agent 架构综述：从 Prompt 到 Context<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 火山引擎开发者社区</li></ol></div></div><footer class="page-meta"><!----><!----></footer><!----><div class="reco-valine-wrapper"><div id="valine"></div></div></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/AI/1.html#术语概念" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="术语概念"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->术语概念<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#大语言模型" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="大语言模型"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->大语言模型<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/AI/1.html#ai-agent" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="AI Agent"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AI Agent<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#agents与agentic-workflow的区别" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Agents与Agentic Workflow的区别"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Agents与Agentic Workflow的区别<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#ai-agent框架" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="AI agent框架"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AI agent框架<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#multi-agent框架" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Multi-Agent框架"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Multi-Agent框架<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#langchain" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="LangChain"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->LangChain<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#langgraph" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="LangGraph"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->LangGraph<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#评估-ai-agent-效果的标准" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="评估 AI Agent 效果的标准"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->评估 AI Agent 效果的标准<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#评测的流程" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="评测的流程"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->评测的流程<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#实际落地过程中的主要挑战" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="实际落地过程中的主要挑战"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实际落地过程中的主要挑战<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/AI/1.html#rag" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="RAG"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->RAG<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#rag工作流程" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="RAG工作流程"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->RAG工作流程<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#rag架构分类" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="RAG架构分类"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->RAG架构分类<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#高级-rag-探究" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="高级 RAG 探究"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->高级 RAG 探究<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#b站利用rag结合llm实现快速获取数据" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="B站利用RAG结合LLM实现快速获取数据"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->B站利用RAG结合LLM实现快速获取数据<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#agentic-rag-智能体驱动型rag" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Agentic RAG（智能体驱动型RAG）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Agentic RAG（智能体驱动型RAG）<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/AI/1.html#prompt-and-context" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Prompt and Context"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Prompt and Context<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#优质提示词原则" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="优质提示词原则"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->优质提示词原则<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#prompt-engineering-的核心技术" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Prompt Engineering 的核心技术"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Prompt Engineering 的核心技术<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#context-engineering" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="Context Engineering"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Context Engineering<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blogs/AI/1.html#上下文丰富性与窗口局限性之间的考量" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="上下文丰富性与窗口局限性之间的考量"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->上下文丰富性与窗口局限性之间的考量<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blogs/AI/1.html#参考资料" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="参考资料"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->参考资料<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--></ul></div></main><!--]--></div></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CwN1xCkZ.js" defer></script>
  </body>
</html>
